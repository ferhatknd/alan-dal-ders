import os
import requests
import sqlite3
import functools
from typing import Optional, Callable
import json
import re

def download_and_cache_pdf(url: str, cache_type: str, alan_adi: str = None, additional_info: str = None, alan_id: str = None, alan_db_id: int = None, meb_alan_id: str = None) -> Optional[str]:
    """
    PDF'yi indirir ve organize ÅŸekilde cache'ler.
    
    Args:
        url: PDF URL'si
        cache_type: 'cop', 'dbf', 'dm', 'bom' gibi dosya tipi
        alan_adi: Alan adÄ± (klasÃ¶r adÄ± iÃ§in)
        additional_info: Ek bilgi (sÄ±nÄ±f, dal vb.)
        alan_id: Alan ID'si (organizasyon iÃ§in, opsiyonel)
        alan_db_id: VeritabanÄ± alan ID'si (klasÃ¶r yapÄ±sÄ± iÃ§in)
        meb_alan_id: MEB alan ID'si (02, 08 gibi - klasÃ¶r yapÄ±sÄ± iÃ§in)
    
    Returns:
        Ä°ndirilen dosyanÄ±n yolu veya None
    """
    if not url or not cache_type:
        return None
    
    try:
        # Alan adÄ± yoksa, URL'den bir parÃ§a alarak geÃ§ici bir isim oluÅŸtur
        if not alan_adi:
            safe_alan_adi = url.split('/')[-2] if len(url.split('/')) > 1 else "bilinmeyen_alan"
        else:
            # Merkezi sanitize fonksiyonunu kullan
            safe_alan_adi = sanitize_filename_tr(alan_adi)
        
        # KlasÃ¶r yapÄ±sÄ± belirleme
        if meb_alan_id and cache_type in ['cop', 'dbf', 'dm', 'bom']:
            # MEB ID bazlÄ± organizasyon: {meb_alan_id}_{alan_adi}
            folder_name = f"{meb_alan_id}_{safe_alan_adi}"
        elif alan_db_id and cache_type in ['cop', 'dbf', 'dm', 'bom']:
            # DB ID bazlÄ± organizasyon: {ID:02d}_{alan_adi}
            folder_name = f"{int(alan_db_id):02d}_{safe_alan_adi}"
        else:
            # Eski format: {alan_adi}
            folder_name = safe_alan_adi
            
        cache_dir = os.path.join("data", cache_type, folder_name)
        os.makedirs(cache_dir, exist_ok=True)
        
        # Dosya adÄ±nÄ± URL'den Ã§Ä±kar
        filename = url.split('/')[-1]
        if not filename.lower().endswith(('.pdf', '.rar', '.zip')):
            filename += '.pdf' # VarsayÄ±lan
        
        # Ek bilgi varsa dosya adÄ±na ekle
        if additional_info:
            name_part, ext = os.path.splitext(filename)
            filename = f"{name_part}_{additional_info}{ext}"
        
        file_path = os.path.join(cache_dir, filename)
        
        # Dosya zaten varsa indirme
        if os.path.exists(file_path):
            print(f"ðŸ“ Cache'den alÄ±nÄ±yor: {file_path}")
            return file_path
        
        # PDF'yi indir
        print(f"â¬‡ï¸ Ä°ndiriliyor: {url}")
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        
        # DosyayÄ± kaydet
        with open(file_path, 'wb') as f:
            f.write(response.content)
        
        print(f"ðŸ’¾ Kaydedildi: {file_path}")
        return file_path
        
    except Exception as e:
        print(f"âŒ Dosya indirme hatasÄ± ({url}): {e}")
        return None


def sanitize_filename_tr(name: str) -> str:
    """
    Dosya/klasÃ¶r ismi olarak kullanÄ±labilir hale getir.
    TÃ¼rkÃ§e karakterleri normalize eder ve dosya sistemi uyumlu yapar.
    
    Args:
        name: Normalize edilecek dosya/klasÃ¶r adÄ±
        
    Returns:
        GÃ¼venli dosya/klasÃ¶r adÄ±
    """
    if not name:
        return "bilinmeyen_alan"
    
    # Normalize alan adÄ± (klasÃ¶r adÄ± iÃ§in)
    safe_name = name.replace(' ', '_').replace('/', '_').replace('\\', '_')
    
    # TÃ¼rkÃ§e karakterleri dÃ¼zelt
    safe_name = safe_name.replace('Ã§', 'c').replace('ÄŸ', 'g').replace('Ä±', 'i').replace('Ã¶', 'o').replace('ÅŸ', 's').replace('Ã¼', 'u')
    safe_name = safe_name.replace('Ã‡', 'C').replace('Äž', 'G').replace('Ä°', 'I').replace('Ã–', 'O').replace('Åž', 'S').replace('Ãœ', 'U')
    
    return safe_name


def get_temp_pdf_path(url: str) -> str:
    """
    GeÃ§ici PDF dosyasÄ± iÃ§in gÃ¼venli yol oluÅŸtur
    """
    import hashlib
    url_hash = hashlib.md5(url.encode()).hexdigest()[:8]
    return f"temp_pdf_{url_hash}.pdf"


def normalize_to_title_case_tr(name: str) -> str:
    """
    Bir metni, TÃ¼rkÃ§e karakterleri ve dil kurallarÄ±nÄ± dikkate alarak
    "BaÅŸlÄ±k BiÃ§imine" (Title Case) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r.

    Ã–rnekler:
    - "BÄ°LÄ°ÅžÄ°M TEKNOLOJÄ°LERÄ°" -> "BiliÅŸim Teknolojileri"
    - "gÄ±da ve iÃ§ecek hizmetleri" -> "GÄ±da ve Ä°Ã§ecek Hizmetleri"
    - "ELEKTRÄ°K-ELEKTRONÄ°K TEKNOLOJÄ°SÄ°" -> "Elektrik-Elektronik Teknolojisi"
    - "elektrik-elektronik teknolojisi" -> "Elektrik-Elektronik Teknolojisi"

    Args:
        name: StandartlaÅŸtÄ±rÄ±lacak metin.

    Returns:
        BaÅŸlÄ±k biÃ§imine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ metin.
    """
    if not name:
        return ""

    # Tireyi geÃ§ici olarak Ã¶zel karakter ile deÄŸiÅŸtir (tire Ã¶ncesi/sonrasÄ± boÅŸluklarÄ± da temizle)
    name = name.replace(' - ', '-').replace('- ', '-').replace(' -', '-')
    name = name.replace('-', ' __tire__ ')
    
    # Metni temizle: baÅŸtaki/sondaki boÅŸluklar, Ã§oklu boÅŸluklarÄ± tek boÅŸluÄŸa indirge
    # ve tamamÄ±nÄ± kÃ¼Ã§Ã¼k harfe Ã§evirerek baÅŸla.
    # TÃ¼rkÃ§e'ye Ã¶zgÃ¼ 'Ä°' -> 'i' ve 'I' -> 'Ä±' dÃ¶nÃ¼ÅŸÃ¼mÃ¼ iÃ§in replace kullanÄ±lÄ±r.
    cleaned_name = ' '.join(name.strip().split()).replace('Ä°', 'i').replace('I', 'Ä±').lower()

    # BaÄŸlaÃ§lar gibi kÃ¼Ã§Ã¼k kalmasÄ± gereken kelimeler.
    lowercase_words = ["ve", "ile", "iÃ§in", "de", "da", "ki"]

    words = cleaned_name.split(' ')
    final_words = []

    for word in words:
        if not word:
            continue

        if word == '__tire__':
            # Tire durumunda bir Ã¶nceki kelime ile birleÅŸtir
            if final_words:
                final_words[-1] += '-'
            continue  # Bu kelimeyi atlayÄ±p sonraki kelimeyi bekle
        elif word in lowercase_words and len(final_words) > 0:  # Ä°lk kelime asla kÃ¼Ã§Ã¼k olmasÄ±n
            # Tire modunda isek boÅŸluksuz ekle
            if final_words and final_words[-1].endswith('-'):
                final_words[-1] += word
            else:
                final_words.append(word)
        else:
            capitalized = 'Ä°' + word[1:] if word.startswith('i') else word.capitalize()
            # Tire modunda isek boÅŸluksuz ekle
            if final_words and final_words[-1].endswith('-'):
                final_words[-1] += capitalized
            else:
                final_words.append(capitalized)

    return ' '.join(final_words)

def normalize_alan_adi(alan_adi):
    """
    Alan adÄ±nÄ± normalize eder - bÃ¼yÃ¼k/kÃ¼Ã§Ã¼k harf sorununu Ã§Ã¶zer.
    """
    if not alan_adi:
        return "BelirtilmemiÅŸ"
    
    # Normalize edilmiÅŸ alan adÄ±: Ä°lk harf bÃ¼yÃ¼k, geri kalan kelimeler ilk harfi bÃ¼yÃ¼k
    normalized = alan_adi.strip()
    
    # YaygÄ±n normalizations
    replacements = {
        'AÄ°LE VE TÃœKETÄ°CÄ° HÄ°ZMETLERÄ°': 'Aile ve TÃ¼ketici Hizmetleri',
        'ADALET': 'Adalet',
        'BÄ°LÄ°ÅžÄ°M TEKNOLOJÄ°LERÄ°': 'BiliÅŸim Teknolojileri',
        'METAL TEKNOLOJÄ°SÄ°': 'Metal Teknolojisi',
        'ELEKTRÄ°K ELEKTRONÄ°K TEKNOLOJÄ°SÄ°': 'Elektrik Elektronik Teknolojisi',
        'MAKÄ°NE TEKNOLOJÄ°SÄ°': 'Makine Teknolojisi',
        'Ä°NÅžAAT TEKNOLOJÄ°SÄ°': 'Ä°nÅŸaat Teknolojisi',
        'ULAÅžTIRMA': 'UlaÅŸtÄ±rma',
        'ENERJÄ°': 'Enerji',
        'Ã‡EVRE': 'Ã‡evre',
        'TARIM': 'TarÄ±m',
        'HAYVANCILIK': 'HayvancÄ±lÄ±k',
        'GIDA': 'GÄ±da',
        'TEKSTÄ°L GÄ°YÄ°M AYAKKABI': 'Tekstil Giyim AyakkabÄ±',
        'KIMYA': 'Kimya',
        'CAM SERAMIK': 'Cam Seramik',
        'AÄžAÃ‡': 'AÄŸaÃ§',
        'KAÄžIT MATBAA': 'KaÄŸÄ±t Matbaa',
        'DERÄ°': 'Deri',
        'FÄ°NANS SÄ°GORTACILIK': 'Finans SigortacÄ±lÄ±k',
        'PAZARLAMA VE SATIÅž': 'Pazarlama ve SatÄ±ÅŸ',
        'LOJÄ°STÄ°K': 'Lojistik',
        'TURÄ°ZM': 'Turizm',
        'SPOR': 'Spor',
        'SANAT VE TASARIM': 'Sanat ve TasarÄ±m',
        'Ä°LETÄ°ÅžÄ°M': 'Ä°letiÅŸim',
        'DÄ°N HÄ°ZMETLERÄ°': 'Din Hizmetleri'
    }
    
    # Ã–nce exact match kontrol et
    if normalized.upper() in replacements:
        return replacements[normalized.upper()]
    
    # Manuel replacement yoksa, normalize_to_title_case_tr kullan
    return normalize_to_title_case_tr(normalized)

def extract_meb_id_from_urls(cop_url=None, dbf_urls=None):
    """
    URL'lerden MEB ID'sini Ã§Ä±karÄ±r.
    Ã‡Ã–P ve DBF URL'lerini tarar ve ID'yi bulur.
    
    Args:
        cop_url: Ã‡Ã–P URL'si (JSON veya string)
        dbf_urls: DBF URL'leri (JSON veya dict)
        
    Returns:
        str: MEB ID'si ("01", "02", vb.) veya None
    """
    urls_to_check = []
    
    # Ã‡Ã–P URL'lerini ekle
    if cop_url:
        try:
            if isinstance(cop_url, str) and cop_url.startswith('{'):
                cop_data = json.loads(cop_url)
                if isinstance(cop_data, dict):
                    urls_to_check.extend(cop_data.values())
            else:
                urls_to_check.append(cop_url)
        except (json.JSONDecodeError, AttributeError):
            urls_to_check.append(cop_url)
    
    # DBF URL'lerini ekle
    if dbf_urls:
        try:
            if isinstance(dbf_urls, str):
                dbf_data = json.loads(dbf_urls)
            else:
                dbf_data = dbf_urls
                
            if isinstance(dbf_data, dict):
                urls_to_check.extend(dbf_data.values())
        except (json.JSONDecodeError, AttributeError, TypeError):
            pass
    
    # URL'lerden MEB ID'sini Ã§Ä±kar
    for url in urls_to_check:
        if isinstance(url, str):
            # Ã‡Ã–P URL'lerinden: cop9, cop10, cop11, cop12
            cop_match = re.search(r'cop(\d+)', url)
            if cop_match:
                continue  # Ã‡Ã–P'te sÄ±nÄ±f bilgisi var, MEB ID yok
            
            # DBF URL'lerinden: dbf9, dbf10, dbf11, dbf12
            dbf_match = re.search(r'dbf(\d+)', url)
            if dbf_match:
                continue  # DBF'te sÄ±nÄ±f bilgisi var, MEB ID yok
            
            # Genel URL pattern'i: alan_id parameter'i
            alan_id_match = re.search(r'alan_id=(\d+)', url)
            if alan_id_match:
                meb_id = alan_id_match.group(1)
                # 2 haneli format'a Ã§evir
                return f"{int(meb_id):02d}"
            
            # Dosya adÄ±ndan Ã§Ä±karma: /upload/dbf9/01_adalet.rar
            file_match = re.search(r'/(\d{2})_[^/]+\.(rar|zip|pdf)$', url)
            if file_match:
                return file_match.group(1)
    
    return None


def get_or_create_alan(cursor, alan_adi, meb_alan_id=None, cop_url=None, dbf_urls=None):
    """
    Alan kaydÄ± bulur veya oluÅŸturur. 
    Ã‡Ã–P URL'leri JSON formatÄ±nda birleÅŸtirir.
    Alan adÄ±nÄ± normalize eder.
    MEB ID yoksa URL'lerden Ã§Ä±karmaya Ã§alÄ±ÅŸÄ±r.
    """
    normalized_alan_adi = normalize_alan_adi(alan_adi)
    
    cursor.execute("SELECT id, cop_url, meb_alan_id FROM temel_plan_alan WHERE alan_adi = ?", (normalized_alan_adi,))
    result = cursor.fetchone()
    
    if result:
        alan_id, existing_cop_url, existing_meb_alan_id = result
        
        # Mevcut Ã‡Ã–P URL'leri ile yeni URL'i birleÅŸtir
        updated_cop_urls = existing_cop_url
        if cop_url:
            # EÄŸer cop_url zaten JSON string ise direkt kullan
            try:
                if cop_url.startswith('{') and cop_url.endswith('}'):
                    json.loads(cop_url)  # GeÃ§erli JSON mu kontrolÃ¼
                    updated_cop_urls = cop_url  # Yeni JSON'u direkt kullan
                else:
                    # Tek URL ise merge fonksiyonunu kullan
                    updated_cop_urls = merge_cop_urls(existing_cop_url, cop_url)
            except (json.JSONDecodeError, AttributeError):
                # JSON deÄŸilse normal merge iÅŸlemi
                updated_cop_urls = merge_cop_urls(existing_cop_url, cop_url)
            
        # MEB Alan ID'sini gÃ¼ncelle (eÄŸer yoksa)
        updated_meb_alan_id = existing_meb_alan_id or meb_alan_id
        
        # EÄŸer hala MEB ID yoksa, URL'lerden Ã§Ä±karmaya Ã§alÄ±ÅŸ
        if not updated_meb_alan_id:
            extracted_id = extract_meb_id_from_urls(updated_cop_urls, dbf_urls)
            if extracted_id:
                updated_meb_alan_id = extracted_id
                print(f"      ðŸ” MEB ID URL'den Ã§Ä±karÄ±ldÄ±: {alan_adi} -> {extracted_id}")
        
        cursor.execute("""
            UPDATE temel_plan_alan 
            SET cop_url = ?, meb_alan_id = ?
            WHERE id = ?
        """, (updated_cop_urls, updated_meb_alan_id, alan_id))
        
        return alan_id
    else:
        # DBF URLs'i JSON string olarak sakla
        dbf_urls_json = json.dumps(dbf_urls) if dbf_urls else None
        
        # Ã‡Ã–P URL'ini JSON formatÄ±nda sakla
        if not cop_url:
            cop_url_json = json.dumps({})
        else:
            # EÄŸer cop_url zaten JSON string ise direkt kullan
            try:
                # JSON string olup olmadÄ±ÄŸÄ±nÄ± kontrol et
                if cop_url.startswith('{') and cop_url.endswith('}'):
                    json.loads(cop_url)  # GeÃ§erli JSON mu kontrolÃ¼
                    cop_url_json = cop_url
                else:
                    # Tek URL ise JSON'a Ã§evir
                    cop_url_json = json.dumps({"default": cop_url})
            except (json.JSONDecodeError, AttributeError):
                # JSON deÄŸilse tek URL olarak kaydet
                cop_url_json = json.dumps({"default": cop_url})
        
        # MEB ID yoksa URL'lerden Ã§Ä±karmaya Ã§alÄ±ÅŸ
        if not meb_alan_id:
            extracted_id = extract_meb_id_from_urls(cop_url_json, dbf_urls_json)
            if extracted_id:
                meb_alan_id = extracted_id
                print(f"      ðŸ” MEB ID URL'den Ã§Ä±karÄ±ldÄ±: {alan_adi} -> {extracted_id}")
        
        cursor.execute("""
            INSERT INTO temel_plan_alan (alan_adi, meb_alan_id, cop_url, dbf_urls) 
            VALUES (?, ?, ?, ?)
        """, (normalized_alan_adi, meb_alan_id, cop_url_json, dbf_urls_json))
        return cursor.lastrowid

def merge_cop_urls(existing_cop_url, new_cop_url):
    """
    Mevcut Ã‡Ã–P URL'leri ile yeni URL'i birleÅŸtirir.
    JSON formatÄ±nda saklar.
    """
    try:
        # Mevcut URL'leri parse et
        if existing_cop_url:
            if existing_cop_url.startswith('{'):
                # Zaten JSON formatÄ±nda
                existing_urls = json.loads(existing_cop_url)
            else:
                # Eski format (string), JSON'a Ã§evir
                existing_urls = {"default": existing_cop_url}
        else:
            existing_urls = {}
        
        # Yeni URL'i ekle (sÄ±nÄ±f bazÄ±nda unique key oluÅŸtur)
        if new_cop_url:
            # URL'den sÄ±nÄ±f bilgisini Ã§Ä±karmaya Ã§alÄ±ÅŸ
            sinif_match = re.search(r'cop(\d+)', new_cop_url)
            if sinif_match:
                sinif = sinif_match.group(1)
                existing_urls[str(sinif)] = new_cop_url
            else:
                # SÄ±nÄ±f bulunamazsa generic key kullan
                existing_urls[f"url_{len(existing_urls) + 1}"] = new_cop_url
        
        return json.dumps(existing_urls)
        
    except Exception as e:
        print(f"Ã‡Ã–P URL merge hatasÄ±: {e}")
        # Hata durumunda yeni URL'i kullan
        return json.dumps({"default": new_cop_url}) if new_cop_url else "{}"

# ====== Database Connection Utilities ======

def find_or_create_database() -> Optional[str]:
    """
    VeritabanÄ± dosyasÄ±nÄ± bulur veya oluÅŸturur.
    
    Returns:
        VeritabanÄ± dosyasÄ±nÄ±n yolu veya None
    """
    import os
    
    db_path = "data/temel_plan.db"
    
    # data klasÃ¶rÃ¼ yoksa oluÅŸtur
    os.makedirs("data", exist_ok=True)
    
    # Database dosyasÄ± yoksa oluÅŸtur
    if not os.path.exists(db_path):
        try:
            # Schema dosyasÄ±ndan tablolarÄ± oluÅŸtur
            schema_path = "data/schema.sql"
            if os.path.exists(schema_path):
                with sqlite3.connect(db_path) as conn:
                    with open(schema_path, 'r', encoding='utf-8') as f:
                        conn.executescript(f.read())
                print(f"âœ… Database initialized: {db_path}")
            else:
                # BoÅŸ database oluÅŸtur
                sqlite3.connect(db_path).close()
                print(f"âš ï¸ Database created without schema: {db_path}")
        except Exception as e:
            print(f"âŒ Database creation failed: {e}")
            return None
    
    return db_path


def with_database(func: Callable) -> Callable:
    """
    Database connection decorator.
    
    Fonksiyonu database cursor'Ä± ile wrap eder.
    Ä°lk parametre olarak cursor geÃ§er.
    
    Usage:
        @with_database
        def my_function(cursor, other_params):
            cursor.execute("SELECT * FROM table")
            return cursor.fetchall()
    """
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        db_path = find_or_create_database()
        if not db_path:
            return {"error": "Database not found", "success": False}
        
        try:
            with sqlite3.connect(db_path) as conn:
                # Row factory ile dict-style access
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                # Ä°lk parametre olarak cursor'Ä± geÃ§
                return func(cursor, *args, **kwargs)
                
        except Exception as e:
            print(f"âŒ Database error in {func.__name__}: {e}")
            return {"error": str(e), "success": False}
    
    return wrapper


def with_database_json(func: Callable) -> Callable:
    """
    Database connection decorator for Flask endpoints.
    
    Hata durumunda JSON response dÃ¶ner.
    
    Usage:
        @app.route('/api/endpoint')
        @with_database_json
        def my_endpoint(cursor):
            # cursor kullan
            return {"data": result, "success": True}
    """
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        from flask import jsonify
        
        db_path = find_or_create_database()
        if not db_path:
            return jsonify({"error": "Database not found", "success": False}), 500
        
        try:
            with sqlite3.connect(db_path) as conn:
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                result = func(cursor, *args, **kwargs)
                
                # Tuple response durumu (Flask endpoint'leri iÃ§in)
                if isinstance(result, tuple):
                    return result
                # Dict response'u jsonify et
                elif isinstance(result, dict):
                    return jsonify(result)
                else:
                    return result
                    
        except Exception as e:
            import datetime
            error_response = {
                "success": False,
                "error": str(e),
                "error_type": "database",
                "timestamp": datetime.datetime.now().isoformat()
            }
            print(f"âŒ Database error in {func.__name__}: {e}")
            return jsonify(error_response), 500
    
    return wrapper


# ====== Ders Management Utilities ======

def create_or_get_ders(cursor, ders_adi, sinif, ders_saati=0, amac='', dm_url='', dbf_url='', bom_url='', cop_url=''):
    """
    Merkezi ders kaydetme fonksiyonu.
    
    Ã–NEMLI: AynÄ± ders adÄ± iÃ§in farklÄ± sÄ±nÄ±flar varsa, sadece en dÃ¼ÅŸÃ¼k sÄ±nÄ±fÄ± saklar.
    Ã–rnek: "Ahilik KÃ¼ltÃ¼rÃ¼ ve GiriÅŸimcilik" hem 11 hem 12'de varsa, sadece 11 kaydedilir.
    
    Args:
        cursor: Database cursor
        ders_adi: Ders adÄ±
        sinif: SÄ±nÄ±f seviyesi (9, 10, 11, 12)
        ders_saati: HaftalÄ±k ders saati (varsayÄ±lan: 0)
        amac: Ders amacÄ± (opsiyonel)
        dm_url: Ders materyali URL'si (opsiyonel)
        dbf_url: DBF dosya URL'si (opsiyonel)
        bom_url: BOM URL'si (opsiyonel)
        cop_url: Ã‡Ã–P URL'si (opsiyonel)
        
    Returns:
        int: Ders ID'si
    """
    if not ders_adi or not sinif:
        return None
    
    # SÄ±nÄ±f deÄŸerini integer'a Ã§evir
    try:
        sinif = int(sinif)
    except (ValueError, TypeError):
        print(f"âŒ GeÃ§ersiz sÄ±nÄ±f deÄŸeri: {sinif}")
        return None
    
    # Ders saati deÄŸerini integer'a Ã§evir
    try:
        ders_saati = int(ders_saati) if ders_saati else 0
    except (ValueError, TypeError):
        ders_saati = 0
    
    # Ã–nce aynÄ± ders adÄ± ile mevcut kayÄ±tlarÄ± kontrol et
    cursor.execute("""
        SELECT id, sinif, ders_saati FROM temel_plan_ders 
        WHERE ders_adi = ?
        ORDER BY sinif ASC
    """, (ders_adi,))
    
    existing_records = cursor.fetchall()
    
    if existing_records:
        # Mevcut kayÄ±tlar var
        existing_lowest_sinif = existing_records[0]['sinif']  # En dÃ¼ÅŸÃ¼k sÄ±nÄ±f
        existing_lowest_id = existing_records[0]['id']
        
        if sinif >= existing_lowest_sinif:
            # Yeni sÄ±nÄ±f daha bÃ¼yÃ¼k veya eÅŸit, mevcut kaydÄ± kullan
            # Ders saati gÃ¼ncelle (0 ise veya yeni deÄŸer daha bÃ¼yÃ¼kse)
            if ders_saati > 0:
                cursor.execute("""
                    UPDATE temel_plan_ders 
                    SET ders_saati = ? 
                    WHERE id = ? AND (ders_saati = 0 OR ders_saati < ?)
                """, (ders_saati, existing_lowest_id, ders_saati))
            
            print(f"      â†» Duplicate ders atlandÄ±: {ders_adi} ({sinif}. sÄ±nÄ±f) - Mevcut: {existing_lowest_sinif}. sÄ±nÄ±f")
            return existing_lowest_id
        else:
            # Yeni sÄ±nÄ±f daha dÃ¼ÅŸÃ¼k, mevcut kayÄ±tlarÄ± sil ve yeni kayÄ±t oluÅŸtur
            print(f"      â†» Daha dÃ¼ÅŸÃ¼k sÄ±nÄ±f bulundu: {ders_adi} ({sinif}. sÄ±nÄ±f) - Eski kayÄ±tlar siliniyor")
            
            # Mevcut kayÄ±tlarÄ± sil (cascade'e gÃ¼venmek yerine manuel temizlik)
            for existing_record in existing_records:
                existing_id = existing_record['id']
                existing_sinif = existing_record['sinif']
                # Ä°liÅŸkili kayÄ±tlarÄ± sil
                cursor.execute("DELETE FROM temel_plan_ders_dal WHERE ders_id = ?", (existing_id,))
                cursor.execute("DELETE FROM temel_plan_ders WHERE id = ?", (existing_id,))
                print(f"      â†» Silindi: {ders_adi} ({existing_sinif}. sÄ±nÄ±f)")
    
    # Yeni ders oluÅŸtur
    cursor.execute("""
        INSERT INTO temel_plan_ders (
            ders_adi, sinif, ders_saati, amac, dm_url, dbf_url, bom_url
        ) VALUES (?, ?, ?, ?, ?, ?, ?)
    """, (
        ders_adi,
        sinif,
        ders_saati,
        amac,
        dm_url,
        dbf_url,
        bom_url
    ))
    
    ders_id = cursor.lastrowid
    print(f"      âž• Yeni ders eklendi: {ders_adi} ({sinif}. sÄ±nÄ±f, {ders_saati} saat)")
    return ders_id


def create_ders_dal_relation(cursor, ders_id, dal_id):
    """
    Ders-Dal iliÅŸkisi oluÅŸturur.
    
    Args:
        cursor: Database cursor
        ders_id: Ders ID'si
        dal_id: Dal ID'si
    """
    if not ders_id or not dal_id:
        return False
    
    cursor.execute("""
        INSERT OR IGNORE INTO temel_plan_ders_dal (ders_id, dal_id, created_at) 
        VALUES (?, ?, datetime('now'))
    """, (ders_id, dal_id))
    
    return True


# ====== Archive Extraction Utilities ======

def extract_archive(archive_path, extract_dir):
    """
    RAR veya ZIP dosyasÄ±nÄ± aÃ§ar. Dosya tipini otomatik algÄ±lar.
    Merkezi arÅŸiv aÃ§ma fonksiyonu.
    
    Args:
        archive_path: AÃ§Ä±lacak arÅŸiv dosyasÄ±nÄ±n yolu
        extract_dir: DosyalarÄ±n Ã§Ä±karÄ±lacaÄŸÄ± dizin
        
    Raises:
        Exception: ArÅŸiv aÃ§Ä±lamadÄ±ÄŸÄ±nda hata fÄ±rlatÄ±r
    """
    import rarfile
    import zipfile
    
    try:
        with open(archive_path, "rb") as f:
            magic = f.read(4)
        
        is_rar = magic == b"Rar!"
        is_zip = magic == b"PK\x03\x04"
        
        if is_rar:
            with rarfile.RarFile(archive_path) as rf:
                rf.extractall(extract_dir)
        elif is_zip:
            with zipfile.ZipFile(archive_path) as zf:
                zf.extractall(extract_dir)
        else:
            raise Exception(f"Desteklenmeyen dosya formatÄ± (magic: {magic})")
    except Exception as e:
        raise Exception(f"ArÅŸiv aÃ§Ä±lÄ±rken hata: {e}")


def scan_directory_for_archives(root_dir, file_extensions=('.rar', '.zip')):
    """
    Belirtilen dizinde arÅŸiv dosyalarÄ±nÄ± tarar.
    
    Args:
        root_dir: Taranacak ana dizin
        file_extensions: Aranacak dosya uzantÄ±larÄ±
        
    Returns:
        List[Dict]: Bulunan arÅŸiv dosyalarÄ± listesi
        Format: [{"path": "dosya_yolu", "name": "dosya_adi", "dir": "klasor_adi"}]
    """
    archives = []
    
    if not os.path.exists(root_dir):
        return archives
    
    for item in os.listdir(root_dir):
        item_path = os.path.join(root_dir, item)
        if not os.path.isdir(item_path):
            continue
        
        for fname in os.listdir(item_path):
            if fname.lower().endswith(file_extensions):
                archive_path = os.path.join(item_path, fname)
                archives.append({
                    "path": archive_path,
                    "name": fname,
                    "dir": item
                })
    
    return archives


def scan_directory_for_pdfs(root_dir, file_extensions=('.pdf', '.docx')):
    """
    Belirtilen dizinde PDF/DOCX dosyalarÄ±nÄ± tarar.
    
    Args:
        root_dir: Taranacak ana dizin  
        file_extensions: Aranacak dosya uzantÄ±larÄ±
        
    Returns:
        List[Dict]: Bulunan PDF dosyalarÄ± listesi
        Format: [{"path": "dosya_yolu", "name": "dosya_adi", "relative_path": "relative_yol"}]
    """
    pdfs = []
    
    if not os.path.exists(root_dir):
        return pdfs
    
    # Recursive search
    for root, dirs, files in os.walk(root_dir):
        for file in files:
            if file.lower().endswith(file_extensions):
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, root_dir)
                
                pdfs.append({
                    "path": file_path,
                    "name": file,
                    "relative_path": relative_path
                })
    
    return pdfs
