#!/usr/bin/env python3
"""
Single Line Tablo Parse Test - KullanÄ±cÄ±nÄ±n verdiÄŸi tek satÄ±rlÄ±k tablo metni
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from modules.utils_dbf1 import ex_kazanim_tablosu, normalize_turkish_text

# KullanÄ±cÄ±nÄ±n verdiÄŸi tek satÄ±rlÄ±k text
single_line_text = """
KAZANIM SAYISI VE SÃœRE TABLOSU Ã–ÄRENME BÄ°RÄ°MÄ° KAZANIM SAYISI DERS SAATÄ° ORAN (%) Defter ve Belgeler 3 20 11 Vergi Dairesi ve Belediye Ä°ÅŸlemleri 2 15 8 Ã‡alÄ±ÅŸma ve Sosyal GÃ¼venlik 3 15 8 Sosyal GÃ¼venlik Ä°ÅŸlemleri 3 25 14 Fatura ve Fatura Yerine GeÃ§en Belgeler 3 40 22 KÄ±ymetli Evraklar ve Menkul KÄ±ymetler 2 15 8 Ä°ÅŸletme Defteri 3 40 22 Serbest Meslek KazanÃ§ Defteri 3 10 7 TOPLAM 22 180 100 Ã–ÄRENME BÄ°RÄ°MÄ° KONULAR Ã–ÄRENME BÄ°RÄ°MÄ° KAZANIMLARI
"""

print("ğŸ” Single Line Tablo Parse Test")
print("=" * 60)

print(f"ğŸ“ Input text length: {len(single_line_text)} chars")
print(f"ğŸ“ First 200 chars: {repr(single_line_text[:200])}")

# Normalized text kontrol
normalized = normalize_turkish_text(single_line_text)
print(f"\nğŸ“ Normalized text (first 200): {normalized[:200]}")

print("\n1. â­ ex_kazanim_tablosu() Test:")
result_str, result_data = ex_kazanim_tablosu(single_line_text)
print(result_str)

print(f"\n2. ğŸ“‹ Structured Data ({len(result_data)} items):")
for i, item in enumerate(result_data, 1):
    print(f"  {i}. {item}")

# Header detection debug
print(f"\n3. ğŸ” Header Detection Debug:")

# Single-line header patterns
table_start_patterns = [
    "KAZANIM SAYISI VE SÃœRE TABLOSU", 
    "DERSÄ°N KAZANIM TABLOSU", 
    "TABLOSU",
]

for pattern in table_start_patterns:
    pattern_normalized = normalize_turkish_text(pattern)
    idx = normalized.find(pattern_normalized)
    print(f"  '{pattern}' â†’ index: {idx}")
    if idx != -1:
        print(f"    Found at position {idx}")
        break

# TOPLAM detection
toplam_idx = single_line_text.find("TOPLAM")
print(f"\n  'TOPLAM' â†’ index: {toplam_idx}")

# Section extraction simulation
if toplam_idx != -1:
    section_before_toplam = single_line_text[:toplam_idx]
    print(f"\n4. ğŸ“ Section before TOPLAM:")
    print(f"Length: {len(section_before_toplam)}")
    print(f"Content: {repr(section_before_toplam[-200:])}")

# Manual pattern matching test
print(f"\n5. ğŸ§ª Manual Pattern Test:")
import re

# Test concatenated text detection
test_section = "Defter ve Belgeler 3 20 11 Vergi Dairesi ve Belediye Ä°ÅŸlemleri 2 15 8 Ã‡alÄ±ÅŸma ve Sosyal GÃ¼venlik 3 15 8"
numbers_in_section = re.findall(r'\d+', test_section)
print(f"Numbers in test section: {numbers_in_section}")
print(f"Count: {len(numbers_in_section)} (concatenated: {len(numbers_in_section) >= 3})")

# Test concatenated pattern
concatenated_pattern = r'([A-ZÃœÄIÅÃ–Ã‡I][A-zÃ¼ÄŸÄ±ÅŸÃ¶Ã§Ä±Ä°\s]+?)\s+(\d+)(?:\s+(\d+(?:[,\.]\d+)?)\s+(\d+(?:[,\.]\d+)?))?(?=\s+[A-ZÃœÄIÅÃ–Ã‡I]|\s+TOPLAM|$)'
matches = re.findall(concatenated_pattern, test_section, re.IGNORECASE)
print(f"Concatenated matches: {len(matches)}")
for match in matches:
    print(f"  - {match}")