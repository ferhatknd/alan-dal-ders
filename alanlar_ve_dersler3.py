import requests
from bs4 import BeautifulSoup
import sys
import time
import unicodedata
import os
import json
from concurrent.futures import ThreadPoolExecutor, as_completed
import pdfplumber
import argparse
import io

def slugify(text):
    """
    Normalizes string, converts to lowercase, removes non-alpha characters,
    and converts spaces to hyphens.
    """
    # TÃ¼rkÃ§e karakterleri Latin karakterlere Ã§evir
    text = ''.join(c for c in unicodedata.normalize('NFD', text) if unicodedata.category(c) != 'Mn')
    # KÃ¼Ã§Ã¼k harfe Ã§evir ve boÅŸluklarÄ± kaldÄ±r
    return "".join(filter(str.isalnum, text.lower()))

BASE_OPTIONS_URL = "https://meslek.meb.gov.tr/cercevelistele.aspx"
BASE_DERS_ALT_URL = "https://meslek.meb.gov.tr/dmgoster.aspx"
BASE_DBF_URL = "https://meslek.meb.gov.tr/dbflistele.aspx"
BASE_BOM_URL = "https://meslek.meb.gov.tr/moduller"

# Sunucu tarafÄ±ndan engellenmemek iÃ§in bir tarayÄ±cÄ± gibi davranan baÅŸlÄ±klar ekleyelim.
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Referer": "https://meslek.meb.gov.tr/"
}

def get_alanlar(sinif_kodu="9"):
    params = {"sinif_kodu": sinif_kodu, "kurum_id": "1"}
    try:
        resp = requests.get(BASE_OPTIONS_URL, params=params, headers=HEADERS, timeout=10)
        resp.raise_for_status()  # 4xx veya 5xx HTTP durum kodlarÄ±nda hata fÄ±rlatÄ±r.
    except requests.exceptions.RequestException as e:
        return []

    resp.encoding = resp.apparent_encoding
    soup = BeautifulSoup(resp.text, "html.parser")
    sel = soup.find('select', id="ContentPlaceHolder1_drpalansec")
    if not sel:
        return []
    alanlar = []
    for opt in sel.find_all('option'):
        val = opt.get('value','').strip()
        name = opt.text.strip()
        if val and val not in ("00","0"):
            alanlar.append({"id": val, "isim": name})
    return alanlar

def get_dersler_for_alan(alan_id, alan_adi, sinif_kodu="9"):
    params = {"sinif_kodu": sinif_kodu, "kurum_id": "1", "alan_id": alan_id}
    try:
        resp = requests.get(BASE_DERS_ALT_URL, params=params, headers=HEADERS, timeout=10)
        resp.raise_for_status() # 4xx veya 5xx HTTP durum kodlarÄ±nda hata fÄ±rlatÄ±r.
    except requests.exceptions.RequestException as e:
        return []

    resp.encoding = resp.apparent_encoding
    soup = BeautifulSoup(resp.text, "html.parser")

    dersler = []
    for div in soup.find_all('div', class_='p-0 bg-light'):
        a = div.find('a', href=True)
        if not a: continue
        ul = a.find('ul', class_='list-group')
        if not ul: continue

        # Ders adÄ± â†’ ilk <li>, sÄ±nÄ±f bilgisini iÃ§eriyor
        items = ul.find_all('li')
        ders_adi = items[0].get_text(" ", strip=True)
        # SÄ±nÄ±f bilgisini daha kesin bir ÅŸekilde Ã§Ä±kar
        sinif_text = ""
        for li in items:
            text = li.get_text(" ", strip=True)
            if "SÄ±nÄ±f" in text and any(char.isdigit() for char in text):
                sinif_text = text
                break
        link = requests.compat.urljoin(resp.url, a['href'].strip())

        dersler.append({"isim": ders_adi,
                        "sinif": sinif_text,
                        "link": link})
    if not dersler:
        # Bu durumu Ã§aÄŸÄ±ran fonksiyona bildirmek iÃ§in boÅŸ liste yeterli.
        pass
    return dersler

def get_dbf_data_for_class(sinif_kodu):
    """Belirtilen sÄ±nÄ±f koduna ait DBF verilerini Ã§eker."""
    params = {"sinif_kodu": sinif_kodu, "kurum_id": "1"}
    class_dbf_data = {}
    try:
        response = requests.get(BASE_DBF_URL, params=params, headers=HEADERS, timeout=15)
        response.raise_for_status()
        response.encoding = response.apparent_encoding
        soup = BeautifulSoup(response.text, "html.parser")

        alan_columns = soup.find_all('div', class_='col-lg-3')
        for column in alan_columns:
            ul_tag = column.find('ul', class_='list-group')
            if not ul_tag: continue

            link_tag = ul_tag.find_parent('a', href=True)
            if not link_tag or not (link_tag['href'].endswith('.rar') or link_tag['href'].endswith('.zip')):
                continue

            dbf_link = requests.compat.urljoin(response.url, link_tag['href'])
            
            alan_adi = ""
            tarih = ""

            b_tag = ul_tag.find('b')
            if b_tag:
                alan_adi = b_tag.get_text(strip=True)

            for item in ul_tag.find_all('li'):
                if item.find('i', class_='fa-calendar'):
                    tarih = item.get_text(strip=True)
                    break

            if alan_adi and dbf_link:
                class_dbf_data[alan_adi] = {
                    "link": dbf_link,
                    "guncelleme_tarihi": tarih
                }
    except requests.RequestException as e:
        print(f"DBF Hata: {sinif_kodu}. sÄ±nÄ±f sayfasÄ± Ã§ekilemedi: {e}")
    return sinif_kodu, class_dbf_data

def get_all_dbf_data(siniflar):
    """TÃ¼m sÄ±nÄ±flar iÃ§in DBF verilerini eÅŸzamanlÄ± olarak Ã§eker."""
    all_dbf_data = {}
    with ThreadPoolExecutor(max_workers=len(siniflar)) as executor:
        future_to_sinif = {executor.submit(get_dbf_data_for_class, sinif): sinif for sinif in siniflar}
        for future in as_completed(future_to_sinif):
            try:
                sinif, data = future.result()
                all_dbf_data[sinif] = data
            except Exception as exc:
                print(f"DBF verisi iÅŸlenirken hata: {exc}")
    return all_dbf_data

def get_cop_data_for_class(sinif_kodu):
    """Belirtilen sÄ±nÄ±f koduna ait Ã‡erÃ§eve Ã–ÄŸretim ProgramÄ± (Ã‡Ã–P) verilerini Ã§eker."""
    params = {"sinif_kodu": sinif_kodu, "kurum_id": "1"}
    class_cop_data = {}
    try:
        # Ã‡Ã–P sayfasÄ±, alan listesiyle aynÄ± URL'i kullanÄ±yor
        response = requests.get(BASE_OPTIONS_URL, params=params, headers=HEADERS, timeout=15)
        response.raise_for_status()
        response.encoding = response.apparent_encoding
        soup = BeautifulSoup(response.text, "html.parser")

        alan_columns = soup.find_all('div', class_='col-lg-3')
        for column in alan_columns:
            link_tag = column.find('a', href=True)
            # Linkin bir Ã‡Ã–P PDF'i olduÄŸundan emin olalÄ±m
            if not link_tag or not link_tag['href'].endswith('.pdf') or 'upload/cop' not in link_tag['href']:
                continue

            cop_link = requests.compat.urljoin(response.url, link_tag['href'])
            
            ul_tag = link_tag.find('ul', class_='list-group')
            if not ul_tag: continue

            alan_adi = ""
            guncelleme_yili = ""

            b_tag = ul_tag.find('b')
            if b_tag:
                alan_adi = b_tag.get_text(strip=True)

            for item in ul_tag.find_all('li'):
                if item.find('i', class_='fa-calendar'):
                    tarih_str = item.get_text(strip=True)
                    guncelleme_yili = tarih_str.split('-')[0].strip() if '-' in tarih_str else tarih_str.strip()
                    break

            if alan_adi and cop_link:
                class_cop_data[alan_adi] = {
                    "link": cop_link,
                    "guncelleme_yili": guncelleme_yili
                }
    except requests.RequestException as e:
        print(f"Ã‡Ã–P Hata: {sinif_kodu}. sÄ±nÄ±f sayfasÄ± Ã§ekilemedi: {e}", file=sys.stderr)
    return sinif_kodu, class_cop_data

def get_all_cop_data(siniflar):
    """TÃ¼m sÄ±nÄ±flar iÃ§in Ã‡Ã–P verilerini eÅŸzamanlÄ± olarak Ã§eker."""
    all_cop_data = {}
    with ThreadPoolExecutor(max_workers=len(siniflar)) as executor:
        future_to_sinif = {executor.submit(get_cop_data_for_class, sinif): sinif for sinif in siniflar}
        for future in as_completed(future_to_sinif):
            try:
                sinif, data = future.result()
                all_cop_data[sinif] = data
            except Exception as exc:
                print(f"Ã‡Ã–P verisi iÅŸlenirken hata: {exc}", file=sys.stderr)
    return all_cop_data

def get_aspnet_form_data(soup):
    """Bir BeautifulSoup nesnesinden ASP.NET form verilerini (VIEWSTATE vb.) Ã§Ä±karÄ±r."""
    form_data = {}
    for input_tag in soup.find_all('input', {'type': ['hidden', 'submit', 'text', 'image']}):
        name = input_tag.get('name')
        value = input_tag.get('value', '')
        if name:
            form_data[name] = value
    return form_data

def get_bom_for_alan(alan_id, alan_adi, session):
    """
    Belirtilen bir alan iÃ§in Bireysel Ã–ÄŸrenme Materyalleri (BÃ–M) verilerini Ã§eker.
    Bu fonksiyon, ASP.NET postback'lerini yÃ¶netmek iÃ§in bir session nesnesi kullanÄ±r.
    """
    bom_data = {"dersler": []}
    try:
        # 1. AdÄ±m: Alan ve ders listelerini almak iÃ§in ilk GET isteÄŸi
        initial_resp = session.get(BASE_BOM_URL, headers=HEADERS, timeout=20)
        initial_resp.raise_for_status()
        initial_soup = BeautifulSoup(initial_resp.text, 'html.parser')

        # 2. AdÄ±m: AlanÄ± seÃ§mek ve ders listesini doldurmak iÃ§in ilk POST isteÄŸi
        form_data = get_aspnet_form_data(initial_soup)
        form_data['ctl00$ContentPlaceHolder1$DropDownList1'] = alan_id
        form_data['__EVENTTARGET'] = 'ctl00$ContentPlaceHolder1$DropDownList1'

        ders_list_resp = session.post(BASE_BOM_URL, data=form_data, headers=HEADERS, timeout=20)
        ders_list_resp.raise_for_status()
        ders_list_soup = BeautifulSoup(ders_list_resp.text, 'html.parser')

        # 3. AdÄ±m: Doldurulan ders listesini ayrÄ±ÅŸtÄ±r
        ders_select = ders_list_soup.find('select', {'name': 'ctl00$ContentPlaceHolder1$DropDownList2'})
        if not ders_select:
            return bom_data

        ders_options = ders_select.find_all('option')
        if len(ders_options) <= 1:  # Sadece "SeÃ§iniz" varsa
            return bom_data

        # 4. AdÄ±m: Her bir ders iÃ§in modÃ¼lleri Ã§ek
        for ders_option in ders_options:
            ders_value = ders_option.get('value')
            ders_adi = ders_option.text.strip()
            if not ders_value or ders_value == '0':
                continue

            ders_form_data = get_aspnet_form_data(ders_list_soup)
            ders_form_data['ctl00$ContentPlaceHolder1$DropDownList1'] = alan_id
            ders_form_data['ctl00$ContentPlaceHolder1$DropDownList2'] = ders_value
            ders_form_data['ctl00$ContentPlaceHolder1$Button1'] = 'Listele'

            modul_resp = session.post(BASE_BOM_URL, data=ders_form_data, headers=HEADERS, timeout=20)
            modul_resp.raise_for_status()
            modul_soup = BeautifulSoup(modul_resp.text, 'html.parser')

            # 5. AdÄ±m: ModÃ¼l tablosunu ayrÄ±ÅŸtÄ±r
            ders_modulleri = []
            modul_table = modul_soup.find('table', id='ctl00_ContentPlaceHolder1_GridView1')
            if modul_table:
                for row in modul_table.find_all('tr')[1:]:  # BaÅŸlÄ±k satÄ±rÄ±nÄ± atla
                    cols = row.find_all('td')
                    if len(cols) >= 2:
                        modul_adi = cols[0].get_text(strip=True)
                        link_tag = cols[1].find('a', href=True)
                        if link_tag:
                            full_link = requests.compat.urljoin("https://megep.meb.gov.tr/", link_tag['href'])
                            ders_modulleri.append({"isim": modul_adi, "link": full_link})
            
            if ders_modulleri:
                bom_data["dersler"].append({
                    "ders_adi": ders_adi,
                    "moduller": ders_modulleri
                })

    except requests.RequestException as e:
        print(f"BÃ–M Hata: '{alan_adi}' alanÄ± iÃ§in veri Ã§ekilemedi: {e}", file=sys.stderr)
        return None
    
    return bom_data

def get_all_bom_data(alanlar_listesi):
    """TÃ¼m alanlar iÃ§in BÃ–M verilerini eÅŸ zamanlÄ± olarak Ã§eker."""
    all_bom_data = {}
    with ThreadPoolExecutor(max_workers=5) as executor:
        future_to_alan = {executor.submit(get_bom_for_alan, alan['id'], alan['isim'], requests.Session()): alan for alan in alanlar_listesi if alan['id'] not in ["0", "00"]}
        for future in as_completed(future_to_alan):
            alan = future_to_alan[future]
            try:
                data = future.result()
                if data and data.get("dersler"):
                    all_bom_data[alan['id']] = data
            except Exception as exc:
                print(f"BÃ–M verisi iÅŸlenirken hata ({alan['isim']}): {exc}", file=sys.stderr)
    return all_bom_data

def download_and_parse_pdf(pdf_url):
    """
    Bir URL'den PDF'i indirir, iÃ§eriÄŸini ayrÄ±ÅŸtÄ±rÄ±r ve yapÄ±sal bir sÃ¶zlÃ¼k dÃ¶ndÃ¼rÃ¼r.
    Bu fonksiyon, README'de bahsedilen detaylÄ± ayrÄ±ÅŸtÄ±rma mantÄ±ÄŸÄ± iÃ§in bir baÅŸlangÄ±Ã§ noktasÄ±dÄ±r.
    """
    try:
        response = requests.get(pdf_url, headers=HEADERS, timeout=45, stream=True)
        response.raise_for_status()

        # Gelen iÃ§eriÄŸin PDF olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        content_type = response.headers.get('Content-Type', '').lower()
        if 'application/pdf' not in content_type:
            if pdf_url.endswith(('.rar', '.zip')):
                return {"icerik": f"Bu bir arÅŸiv dosyasÄ±dÄ±r ({os.path.basename(pdf_url)}), otomatik ayrÄ±ÅŸtÄ±rma desteklenmiyor."}
            return {"hata": f"Ä°ndirilen dosya bir PDF deÄŸil. TÃ¼r: {content_type}"}

        # DosyayÄ± hafÄ±zada tutarak iÅŸle
        pdf_file = io.BytesIO(response.content)

        # --- DETAYLI AYRIÅžTIRMA MANTIÄžI (KAZANIM, ÃœNÄ°TE VB.) BURAYA GELECEK ---
        # Ã–rnek olarak, ilk sayfanÄ±n metnini ve toplam sayfa sayÄ±sÄ±nÄ± Ã§ekiyoruz.
        # Bu bÃ¶lÃ¼mÃ¼ kendi karmaÅŸÄ±k ayrÄ±ÅŸtÄ±rma mantÄ±ÄŸÄ±nÄ±zla geniÅŸletebilirsiniz.
        text_content = ""
        page_count = 0
        with pdfplumber.open(pdf_file) as pdf:
            page_count = len(pdf.pages)
            if page_count > 0:
                page = pdf.pages[0]
                text_content = page.extract_text(x_tolerance=2, y_tolerance=2) or ""

        return {
            "ozet": text_content[:500].strip() + "..." if text_content else "Ä°Ã§erik okunamadÄ±.",
            "sayfa_sayisi": page_count
        }
    except requests.RequestException as e:
        return {"hata": f"PDF indirilemedi: {e}"}
    except Exception as e:
        return {"hata": f"PDF ayrÄ±ÅŸtÄ±rÄ±lÄ±rken hata oluÅŸtu: {e}"}

def scrape_data():
    """Verileri Ã§eker ve ilerlemeyi yield ile anlÄ±k olarak bildirir."""
    siniflar = ["9", "10", "11", "12"]
    tum_veri = {}
    link_index = {}
    
    CACHE_FILE = "data/scraped_data.json"

    # AdÄ±m 1: Mevcut Ã¶nbelleÄŸi yÃ¼kle
    if os.path.exists(CACHE_FILE):
        try:
            with open(CACHE_FILE, 'r', encoding='utf-8') as f:
                cached_data = json.load(f)
                tum_veri = cached_data.get("alanlar", {})
                link_index = cached_data.get("ortak_alan_indeksi", {})
                yield {"type": "progress", "message": "Mevcut Ã¶nbellek yÃ¼klendi. Eksik veriler tamamlanacak..."}
        except (IOError, json.JSONDecodeError):
            yield {"type": "warning", "message": "Ã–nbellek dosyasÄ± bozuk, sÄ±fÄ±rdan baÅŸlanÄ±yor."}
            tum_veri = {}
            link_index = {}
    else:
        yield {"type": "progress", "message": "Ã–nbellek bulunamadÄ±, veri Ã§ekme iÅŸlemi baÅŸlatÄ±lÄ±yor..."}

    # AdÄ±m 2: TÃ¼m DBF verilerini en baÅŸta Ã§ek
    yield {"type": "progress", "message": "DBF verileri Ã§ekiliyor..."}
    dbf_data = get_all_dbf_data(siniflar)
    yield {"type": "progress", "message": "DBF verileri Ã§ekildi."}

    yield {"type": "progress", "message": "Ã‡erÃ§eve Ã–ÄŸretim ProgramÄ± (Ã‡Ã–P) verileri Ã§ekiliyor..."}
    cop_data = get_all_cop_data(siniflar)
    yield {"type": "progress", "message": "Ã‡Ã–P verileri Ã§ekildi."}
    
    # AdÄ±m 3: Toplam iÅŸ yÃ¼kÃ¼nÃ¼ hesapla (tÃ¼m alanlarÄ±n sayÄ±sÄ±nÄ± bul)
    all_alanlar_by_sinif = {sinif: get_alanlar(sinif) for sinif in siniflar}
    # BÃ–M iÃ§in kullanÄ±lacak benzersiz alan listesi
    unique_alanlar = list({v['id']:v for k,v_list in all_alanlar_by_sinif.items() for v in v_list}.values())
    total_alan_count = sum(len(alan_list) for alan_list in all_alanlar_by_sinif.values())

    if total_alan_count == 0:
        yield {"type": "warning", "message": "Ä°ÅŸlenecek hiÃ§ alan bulunamadÄ±. Ä°ÅŸlem sonlandÄ±rÄ±lÄ±yor."}
        yield {"type": "done", "data": {"alanlar": {}, "ortak_alan_indeksi": {}}}
        return

    # AdÄ±m 3.5: BÃ–M verilerini Ã§ek
    yield {"type": "progress", "message": "Bireysel Ã–ÄŸrenme Materyalleri (BÃ–M) verileri Ã§ekiliyor..."}
    bom_data = get_all_bom_data(unique_alanlar)
    yield {"type": "progress", "message": "BÃ–M verileri Ã§ekildi. Alanlar iÅŸleniyor..."}

    yield {"type": "progress", "message": f"Toplam {total_alan_count} alan/sÄ±nÄ±f kombinasyonu iÅŸlenecek."}

    processed_alan_count = 0
    start_time = time.time()

    for sinif in siniflar:
        alanlar = all_alanlar_by_sinif[sinif]
        if not alanlar:
            yield {"type": "warning", "message": f"UyarÄ±: {sinif}. sÄ±nÄ±f iÃ§in alan bulunamadÄ±."}
            continue

        for i, alan in enumerate(alanlar):
            # Ä°lerleme ve zaman tahmini
            processed_alan_count += 1
            elapsed_time = time.time() - start_time
            avg_time_per_alan = elapsed_time / processed_alan_count
            remaining_alanlar = total_alan_count - processed_alan_count
            estimated_remaining_time_seconds = remaining_alanlar * avg_time_per_alan
            
            # ZamanÄ± dakika ve saniye olarak formatla
            mins, secs = divmod(estimated_remaining_time_seconds, 60)
            estimation_str = f"Tahmini kalan sÃ¼re: {int(mins)} dakika {int(secs)} saniye"

            alan_id = alan["id"]
            alan_adi = alan["isim"]
            
            # AlanÄ±n zaten iÅŸlenip iÅŸlenmediÄŸini kontrol et (dersler ve dbf linki)
            alan_entry = tum_veri.get(alan_id, {})
            dersler_dolu = alan_entry.get("dersler") and any(d.get("siniflar") and sinif in d["siniflar"] for d in alan_entry["dersler"].values())
            dbf_link_var = sinif in alan_entry.get("dbf_bilgileri", {})
            cop_link_var = sinif in alan_entry.get("cop_bilgileri", {})

            if dersler_dolu and dbf_link_var and cop_link_var:
                yield {
                    "type": "progress",
                    "message": f"[{sinif}. SÄ±nÄ±f] Alan zaten gÃ¼ncel: {alan_adi} ({processed_alan_count}/{total_alan_count})",
                    "estimation": estimation_str
                }
                continue # Bu alanÄ± atla

            yield {
                "type": "progress",
                "message": f"[{sinif}. SÄ±nÄ±f] Alan iÅŸleniyor: {alan_adi} ({processed_alan_count}/{total_alan_count})",
                "estimation": estimation_str
            }
            
            # Alan verisini ve DBF linklerini hazÄ±rla, eksik anahtarlarÄ± gÃ¼venli bir ÅŸekilde ekle
            alan_entry = tum_veri.setdefault(alan_id, {"isim": alan_adi})
            alan_entry.setdefault("dersler", {})
            alan_entry.setdefault("dbf_bilgileri", {})
            alan_entry.setdefault("cop_bilgileri", {})
            alan_entry.setdefault("bom_materyalleri", bom_data.get(alan_id, {}))
            
            # KazÄ±nan DBF verisini ekle
            sinif_dbf_data = dbf_data.get(sinif, {})
            if alan_adi in sinif_dbf_data:
                dbf_info = sinif_dbf_data[alan_adi]
                alan_entry["dbf_bilgileri"][sinif] = dbf_info

                # YENÄ° ADIM: PDF'i indir ve ayrÄ±ÅŸtÄ±r
                yield {
                    "type": "progress",
                    "message": f"  -> DBF indiriliyor/ayrÄ±ÅŸtÄ±rÄ±lÄ±yor: {alan_adi} ({sinif}. SÄ±nÄ±f)"
                }
                parsed_content = download_and_parse_pdf(dbf_info['link'])
                # AyrÄ±ÅŸtÄ±rÄ±lan iÃ§eriÄŸi mevcut bilgiye ekle
                alan_entry["dbf_bilgileri"][sinif]['ayristirilan_veri'] = parsed_content
                if "hata" in parsed_content:
                    yield {"type": "warning", "message": f"  -> UYARI: {alan_adi} DBF ayrÄ±ÅŸtÄ±rÄ±lamadÄ±: {parsed_content['hata']}"}
                else:
                    yield {"type": "progress", "message": f"  -> DBF baÅŸarÄ±yla ayrÄ±ÅŸtÄ±rÄ±ldÄ±."}
            
            # Dersleri sadece gerekliyse Ã§ek
            # YENÄ° ADIM: KazÄ±nan Ã‡Ã–P verisini ekle
            sinif_cop_data = cop_data.get(sinif, {})
            if alan_adi in sinif_cop_data:
                cop_info = sinif_cop_data[alan_adi]
                alan_entry["cop_bilgileri"][sinif] = cop_info
            
            if not dersler_dolu:
                ders_listesi = get_dersler_for_alan(alan_id, alan["isim"], sinif)
                for d in ders_listesi:
                    ders_link = d["link"]
                    # SÄ±nÄ±f numarasÄ±nÄ± "11.SÄ±nÄ±f" metninden Ã§Ä±kar
                    sinif_num = d["sinif"].replace(".SÄ±nÄ±f", "").strip()
                    # Ders linkini anahtar olarak kullanarak dersleri grupla
                    ders_entry = alan_entry["dersler"].setdefault(ders_link, {
                        "isim": d["isim"],
                        "siniflar": set()
                    })
                    ders_entry["siniflar"].add(sinif_num)
                    # Bu dersin (linkin) hangi alanlarda olduÄŸunu takip et
                    link_index.setdefault(ders_link, set()).add(alan_id)

    # JSON uyumluluÄŸu iÃ§in set'leri listeye Ã§evir
    for alan_id in tum_veri:
        for ders_link in tum_veri[alan_id]["dersler"]:
            tum_veri[alan_id]["dersler"][ders_link]["siniflar"] = sorted(list(tum_veri[alan_id]["dersler"][ders_link]["siniflar"]), key=int)
    for link in link_index:
        link_index[link] = sorted(list(link_index[link]))

    yield {"type": "progress", "message": "Ä°ÅŸlem tamamlandÄ±. Veriler birleÅŸtiriliyor..."}
    final_data = {"alanlar": tum_veri, "ortak_alan_indeksi": link_index}
    
    # Veriyi dosyaya kaydet
    try:
        os.makedirs(os.path.dirname(CACHE_FILE), exist_ok=True)
        with open(CACHE_FILE, 'w', encoding='utf-8') as f:
            json.dump(final_data, f, ensure_ascii=False, indent=2)
        yield {"type": "progress", "message": f"Veri baÅŸarÄ±yla {CACHE_FILE} dosyasÄ±na kaydedildi/gÃ¼ncellendi."}
    except IOError as e:
        yield {"type": "error", "message": f"HATA: Ã–nbellek dosyasÄ± yazÄ±lamadÄ±: {e}"}

    # Son olarak, tÃ¼m veriyi 'done' tipiyle gÃ¶nder
    yield {"type": "done", "data": final_data}

def print_full_summary():
    """
    Runs the full scrape and prints a summary of all data to the terminal.
    This was the original main() function's behavior.
    """
    # Generator'dan gelen tÃ¼m veriyi topla
    print("TÃ¼m veriler Ã§ekiliyor ve Ã¶zet oluÅŸturuluyor... (Bu iÅŸlem uzun sÃ¼rebilir)")
    final_data = None
    for item in scrape_data():
        # Sadece ilerleme ve uyarÄ±larÄ± gÃ¶ster, Ã§ok fazla Ã§Ä±ktÄ± olmasÄ±n
        if item['type'] in ['progress', 'warning', 'error']:
            print(f"  -> {item['message']}", file=sys.stderr)
        if item['type'] == 'done':
            final_data = item['data']
            break
    
    if not final_data:
        print("Veri Ã§ekme iÅŸlemi baÅŸarÄ±sÄ±z oldu veya veri bulunamadÄ±.", file=sys.stderr)
        return

    tum_veri = final_data["alanlar"]
    link_index = final_data["ortak_alan_indeksi"]

    # ðŸ–¨ï¸ Terminal Ã§Ä±ktÄ±sÄ±
    for alan_id, alan_data in sorted(tum_veri.items(), key=lambda item: item[1]['isim']):
        print(f"\n{alan_data['isim']} ({alan_id})")
        
        # DBF Linklerini yazdÄ±r
        if alan_data.get("dbf_bilgileri") and any(alan_data["dbf_bilgileri"].values()):
            print("  Ders Bilgi FormlarÄ±:")
            for sinif, dbf_info in sorted(alan_data["dbf_bilgileri"].items()):
                tarih_str = f" (GÃ¼ncelleme: {dbf_info['guncelleme_tarihi']})" if dbf_info.get('guncelleme_tarihi') else ""
                print(f"  -> {sinif}. SÄ±nÄ±f: {dbf_info['link']}{tarih_str}")

        # Ã‡Ã–P Linklerini yazdÄ±r
        if alan_data.get("cop_bilgileri") and any(alan_data["cop_bilgileri"].values()):
            print("  Ã‡erÃ§eve Ã–ÄŸretim ProgramlarÄ± (Ã‡Ã–P):")
            for sinif, cop_info in sorted(alan_data["cop_bilgileri"].items()):
                yil_str = f" (YÄ±l: {cop_info['guncelleme_yili']})" if cop_info.get('guncelleme_yili') else ""
                print(f"  -> {sinif}. SÄ±nÄ±f: {cop_info['link']}{yil_str}")

        # BÃ–M Materyallerini yazdÄ±r
        if alan_data.get("bom_materyalleri") and alan_data.get("bom_materyalleri", {}).get("dersler"):
            print("  Bireysel Ã–ÄŸrenme Materyalleri (BÃ–M):")
            for ders in alan_data["bom_materyalleri"]["dersler"]:
                print(f"    - Ders: {ders['ders_adi']}")
                if ders.get("moduller"):
                    for modul in ders["moduller"]:
                        print(f"      -> {modul['isim']}: {modul['link']}")
        
        # Dersleri isme gÃ¶re sÄ±rala
        sorted_dersler = sorted(alan_data["dersler"].items(), key=lambda item: item[1]["isim"])
        if sorted_dersler:
            print("  Ders Materyalleri (PDF):")
            for ders_link, d in sorted_dersler:
                # SÄ±nÄ±flarÄ± birleÅŸtir: ["11", "12"] -> "11-12"
                sinif_str = "-".join(d['siniflar'])
                sinif_display_str = f"({sinif_str}. SÄ±nÄ±f)"
                # Ortak alan bilgisini oluÅŸtur
                ortak_alanlar = link_index.get(ders_link, [])
                ortak_str = ""
                if len(ortak_alanlar) > 1:
                    ortak_str = f" ({len(ortak_alanlar)} ortak alan)"
                print(f"  -> {d['isim']} {sinif_display_str}{ortak_str}")

    print("\n==== Ã–zet ====")
    toplam_alan = len(tum_veri)
    alan_bazinda_toplam_ders = sum(len(alan_data["dersler"]) for alan_data in tum_veri.values())
    benzersiz_toplam_ders = len({l for l in link_index})
    print(f"Toplam Alan: {toplam_alan}")
    print(f"Alan BazÄ±nda Toplam Ders: {alan_bazinda_toplam_ders}")
    print(f"Benzersiz Toplam Ders: {benzersiz_toplam_ders}")

def main():
    parser = argparse.ArgumentParser(description="MEB veri Ã§ekme ve test aracÄ±.")
    parser.add_argument(
        '--test', 
        choices=['bom', 'dbf', 'cop', 'dersler', 'alanlar'], 
        help="Belirli bir modÃ¼lÃ¼ test et: 'bom', 'dbf', 'cop', 'dersler', 'alanlar'."
    )
    parser.add_argument(
        '--alan-id', 
        type=str, 
        help="Test iÃ§in belirli bir alan ID'si (Ã¶rn: '04' BiliÅŸim Teknolojileri iÃ§in)."
    )
    parser.add_argument(
        '--sinif', 
        type=str, 
        help="Test iÃ§in belirli bir sÄ±nÄ±f (Ã¶rn: '9', '10', '11', '12')."
    )
    args = parser.parse_args()

    if not args.test:
        # Test argÃ¼manÄ± yoksa, tam Ã¶zet fonksiyonunu Ã§alÄ±ÅŸtÄ±r
        print_full_summary()
        return

    print(f"ðŸš€ Test modu baÅŸlatÄ±ldÄ±: {args.test}")
    
    if args.test == 'alanlar':
        sinif = args.sinif if args.sinif else "9"
        print(f"Alanlar {sinif}. sÄ±nÄ±f iÃ§in Ã§ekiliyor...")
        data = get_alanlar(sinif)
        print(json.dumps(data, indent=2, ensure_ascii=False))

    elif args.test == 'dersler':
        if not args.alan_id:
            print("Hata: 'dersler' testi iÃ§in --alan-id gereklidir.", file=sys.stderr)
            return
        sinif = args.sinif if args.sinif else "9"
        print(f"Dersler, Alan ID: {args.alan_id}, SÄ±nÄ±f: {sinif} iÃ§in Ã§ekiliyor...")
        data = get_dersler_for_alan(args.alan_id, "Test AlanÄ±", sinif)
        print(json.dumps(data, indent=2, ensure_ascii=False))

    elif args.test == 'dbf':
        sinif = args.sinif if args.sinif else "9"
        print(f"DBF verileri {sinif}. sÄ±nÄ±f iÃ§in Ã§ekiliyor...")
        _, data = get_dbf_data_for_class(sinif)
        print(json.dumps(data, indent=2, ensure_ascii=False))

    elif args.test == 'cop':
        sinif = args.sinif if args.sinif else "9"
        print(f"Ã‡Ã–P verileri {sinif}. sÄ±nÄ±f iÃ§in Ã§ekiliyor...")
        _, data = get_cop_data_for_class(sinif)
        print(json.dumps(data, indent=2, ensure_ascii=False))

    elif args.test == 'bom':
        if not args.alan_id:
            print("Hata: 'bom' testi iÃ§in --alan-id gereklidir.", file=sys.stderr)
            return
        print(f"BÃ–M verileri Alan ID: {args.alan_id} iÃ§in Ã§ekiliyor...")
        # get_bom_for_alan bir session nesnesi bekliyor, test iÃ§in yeni bir tane oluÅŸturalÄ±m.
        data = get_bom_for_alan(args.alan_id, "Test AlanÄ±", requests.Session())
        print(json.dumps(data, indent=2, ensure_ascii=False))


if __name__ == "__main__":
    main()
