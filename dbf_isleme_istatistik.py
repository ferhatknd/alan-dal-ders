#!/usr/bin/env python3
"""
DBF Dosya Ä°ÅŸleme Ä°statistik Script'i
====================================

Bu script data/dbf dizinindeki tÃ¼m PDF ve DOCX dosyalarÄ±nÄ± iÅŸler ve aÅŸaÄŸÄ±daki istatistikleri sunar:
- Toplam iÅŸlenen dosya sayÄ±sÄ±
- BaÅŸlÄ±k Ã§Ä±karÄ±lan dosya sayÄ±sÄ±
- BaÅŸlÄ±klarda eÅŸleÅŸme olmayan dosya sayÄ±sÄ± ve adresleri
- DetaylÄ± eÅŸleÅŸme istatistikleri

KullanÄ±m:
    python dbf_isleme_istatistik.py

Bu script extract_olcme.py'deki fonksiyonlarÄ± kullanÄ±r.
"""

import fitz  # PyMuPDF
import re
import os
import sys
import time
from datetime import datetime

# extract_olcme.py'den fonksiyonlarÄ± import et
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from extract_olcme import ex_kazanim_tablosu, extract_ob_tablosu, komutlar, normalize_turkish_text, ex_temel_bilgiler

class DBFProcessingStats:
    """DBF dosya iÅŸleme istatistiklerini takip eden sÄ±nÄ±f"""
    
    def __init__(self):
        self.total_files = 0
        self.processed_files = 0
        self.files_with_headers = 0
        self.files_with_matching_headers = 0
        self.files_with_perfect_matches = 0
        self.files_without_matches = []
        self.processing_errors = []
        self.header_extraction_details = []
        self.perfect_match_courses = []
        self.start_time = None
        self.end_time = None
        
    def start_processing(self):
        """Ä°ÅŸleme baÅŸlangÄ±cÄ±nÄ± kaydet"""
        self.start_time = time.time()
        print(f"ğŸ“Š DBF Dosya Ä°ÅŸleme Ä°statistik Analizi")
        print(f"â° BaÅŸlangÄ±Ã§ ZamanÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)
        
    def process_file(self, file_path):
        """Tek dosyayÄ± iÅŸle ve istatistikleri gÃ¼ncelle"""
        self.processed_files += 1
        file_stats = {
            'path': file_path,
            'filename': os.path.basename(file_path),
            'has_headers': False,
            'has_matches': False,
            'is_perfect_match': False,
            'course_name': None,
            'header_count': 0,
            'match_count': 0,
            'no_match_headers': [],
            'error': None
        }
        
        try:
            print(f"\nğŸ“„ [{self.processed_files}/{self.total_files}] {file_stats['filename']}")
            print("-" * 60)
            
            # DosyayÄ± oku
            doc = fitz.open(file_path)
            full_text = ""
            for page in doc:
                full_text += page.get_text() + "\n"
            doc.close()
            
            # Metni normalize et
            full_text = re.sub(r'\s+', ' ', full_text)
            
            if not full_text.strip():
                file_stats['error'] = "Dosya iÃ§eriÄŸi boÅŸ"
                self.processing_errors.append(file_stats)
                print("âŒ HATA: Dosya iÃ§eriÄŸi boÅŸ")
                return file_stats
            
            # Ders adÄ±nÄ± Ã§Ä±kar
            temel_bilgiler = ex_temel_bilgiler(full_text)
            for key, value in temel_bilgiler.items():
                if "ADI" in key.upper() and value.strip():
                    file_stats['course_name'] = value.strip()
                    print(f"ğŸ“š Ders AdÄ±: {file_stats['course_name']}")
                    break
            
            if not file_stats['course_name']:
                print("âš ï¸  Ders adÄ± bulunamadÄ±")
            
            # KazanÄ±m tablosunu Ã§Ä±kar
            kazanim_tablosu_str, kazanim_tablosu_data = ex_kazanim_tablosu(full_text=full_text)
            
            if kazanim_tablosu_data:
                file_stats['has_headers'] = True
                file_stats['header_count'] = len(kazanim_tablosu_data)
                self.files_with_headers += 1
                
                print(f"âœ… BaÅŸlÄ±k Ã‡Ä±karma: {file_stats['header_count']} baÅŸlÄ±k bulundu")
                
                # Ã–ÄŸrenme birimi analizi
                result = extract_ob_tablosu(full_text=full_text)
                
                # EÅŸleÅŸme analizini yap
                match_analysis = self._analyze_matches(result, kazanim_tablosu_data)
                file_stats.update(match_analysis)
                
                if file_stats['match_count'] > 0:
                    file_stats['has_matches'] = True
                    self.files_with_matching_headers += 1
                    print(f"ğŸ¯ EÅŸleÅŸme Analizi: {file_stats['match_count']}/{file_stats['header_count']} baÅŸlÄ±k eÅŸleÅŸti")
                    
                    # Tam eÅŸleÅŸme kontrolÃ¼
                    if file_stats['match_count'] == file_stats['header_count']:
                        file_stats['is_perfect_match'] = True
                        self.files_with_perfect_matches += 1
                        if file_stats['course_name']:
                            self.perfect_match_courses.append({
                                'course_name': file_stats['course_name'],
                                'filename': file_stats['filename'],
                                'path': file_stats['path'],
                                'header_count': file_stats['header_count']
                            })
                        print("ğŸ† TAM EÅLEÅME: TÃ¼m baÅŸlÄ±klar eÅŸleÅŸti!")
                else:
                    print(f"âš ï¸  EÅŸleÅŸme Analizi: HiÃ§bir baÅŸlÄ±k eÅŸleÅŸmedi")
                    self.files_without_matches.append(file_stats)
                
                # EÅŸleÅŸmeyen baÅŸlÄ±klarÄ± gÃ¶ster
                if file_stats['no_match_headers']:
                    print(f"âŒ EÅŸleÅŸmeyen BaÅŸlÄ±klar: {', '.join(file_stats['no_match_headers'])}")
                    
            else:
                file_stats['error'] = "KazanÄ±m tablosu bulunamadÄ±"
                print(f"âŒ HATA: KazanÄ±m tablosu bulunamadÄ±")
                self.processing_errors.append(file_stats)
                
        except Exception as e:
            file_stats['error'] = str(e)
            self.processing_errors.append(file_stats)
            print(f"âŒ HATA: {str(e)}")
        
        self.header_extraction_details.append(file_stats)
        return file_stats
    
    def _analyze_matches(self, ob_result, kazanim_data):
        """Ã–ÄŸrenme birimi eÅŸleÅŸme sonuÃ§larÄ±nÄ± analiz et"""
        match_count = 0
        no_match_headers = []
        
        if not ob_result or "eÅŸleÅŸme" not in ob_result:
            return {
                'match_count': 0,
                'no_match_headers': [item['title'] for item in kazanim_data]
            }
        
        # EÅŸleÅŸme satÄ±rlarÄ±nÄ± analiz et
        lines = ob_result.split('\n')
        for line in lines:
            if "eÅŸleÅŸme" in line and "->" in line:
                # Format: "1-BaÅŸlÄ±k AdÄ± (3) -> 1 eÅŸleÅŸme"
                if " -> 0 eÅŸleÅŸme" in line:
                    # EÅŸleÅŸmeyen baÅŸlÄ±ÄŸÄ± Ã§Ä±kar
                    header_part = line.split(" -> 0 eÅŸleÅŸme")[0]
                    if "-" in header_part:
                        header_name = header_part.split("-", 1)[1]
                        header_name = header_name.split(" (")[0].strip()
                        no_match_headers.append(header_name)
                elif ("1 eÅŸleÅŸme" in line or "eÅŸleÅŸme (alternatif)" in line) and " -> 0 eÅŸleÅŸme" not in line:
                    match_count += 1
        
        return {
            'match_count': match_count,
            'no_match_headers': no_match_headers
        }
    
    def finish_processing(self):
        """Ä°ÅŸlemi tamamla ve Ã¶zet raporu hazÄ±rla"""
        self.end_time = time.time()
        processing_time = self.end_time - self.start_time
        
        print("\n" + "=" * 80)
        print("ğŸ“Š Ã–ZET Ä°STATÄ°STÄ°KLER")
        print("=" * 80)
        
        print(f"â±ï¸  Toplam Ä°ÅŸlem SÃ¼resi: {processing_time:.2f} saniye")
        print(f"ğŸ“ Toplam Dosya SayÄ±sÄ±: {self.total_files}")
        print(f"âœ… Ä°ÅŸlenen Dosya SayÄ±sÄ±: {self.processed_files}")
        print(f"ğŸ“‹ BaÅŸlÄ±k Ã‡Ä±karÄ±lan Dosya SayÄ±sÄ±: {self.files_with_headers}")
        print(f"ğŸ¯ BaÅŸlÄ±klarda EÅŸleÅŸme Olan Dosya SayÄ±sÄ±: {self.files_with_matching_headers}")
        print(f"ğŸ† TAM EÅŸleÅŸme Olan Dosya SayÄ±sÄ±: {self.files_with_perfect_matches}")
        print(f"âš ï¸  BaÅŸlÄ±klarda EÅŸleÅŸme Olmayan Dosya SayÄ±sÄ±: {len(self.files_without_matches)}")
        print(f"âŒ Hata Alan Dosya SayÄ±sÄ±: {len(self.processing_errors)}")
        
        # YÃ¼zdelik oranlar
        if self.processed_files > 0:
            success_rate = (self.files_with_headers / self.processed_files) * 100
            match_rate = (self.files_with_matching_headers / self.processed_files) * 100
            perfect_rate = (self.files_with_perfect_matches / self.processed_files) * 100
            print(f"\nğŸ“ˆ BAÅARI ORANLARI:")
            print(f"   ğŸ“‹ BaÅŸlÄ±k Ã‡Ä±karma BaÅŸarÄ± OranÄ±: {success_rate:.1f}%")
            print(f"   ğŸ¯ EÅŸleÅŸme BaÅŸarÄ± OranÄ±: {match_rate:.1f}%")
            print(f"   ğŸ† Tam EÅŸleÅŸme OranÄ±: {perfect_rate:.1f}%")
        
        # TAM EÅLEÅMELÄ° DERSLER LÄ°STESÄ°
        if self.perfect_match_courses:
            print(f"\nğŸ† TAM EÅLEÅME OLAN DERSLER ({len(self.perfect_match_courses)} adet):")
            print("-" * 60)
            for i, course in enumerate(self.perfect_match_courses, 1):
                course_name = course.get('course_name', 'Ä°sim BulunamadÄ±')
                print(f"{i:2d}. {course_name}")
                print(f"     ğŸ“„ {course['filename']} ({course['header_count']} baÅŸlÄ±k)")
                print(f"     ğŸ“‚ {course['path']}")
                print()
        else:
            print(f"\nğŸ† TAM EÅLEÅME OLAN DERSLER ({self.files_with_perfect_matches} adet):")
            print("âš ï¸  Ders adlarÄ± Ã§Ä±karÄ±lamadÄ±. Sadece dosya sayÄ±sÄ± mevcut.")
        
        # EÅŸleÅŸmeyen dosyalarÄ±n listesi
        if self.files_without_matches:
            print(f"\nâš ï¸  EÅLEÅMEYÄ° OLMAYAN DOSYALAR ({len(self.files_without_matches)} adet):")
            print("-" * 60)
            for i, file_stats in enumerate(self.files_without_matches, 1):
                course_name_info = f" - {file_stats['course_name']}" if file_stats['course_name'] else ""
                print(f"{i:2d}. {file_stats['filename']}{course_name_info}")
                print(f"     ğŸ“‚ {file_stats['path']}")
                if file_stats['no_match_headers']:
                    print(f"     âŒ EÅŸleÅŸmeyen baÅŸlÄ±klar: {', '.join(file_stats['no_match_headers'])}")
                print()
        
        # Hata alan dosyalarÄ±n listesi
        if self.processing_errors:
            print(f"\nâŒ HATA ALAN DOSYALAR ({len(self.processing_errors)} adet):")
            print("-" * 60)
            for i, file_stats in enumerate(self.processing_errors, 1):
                course_name_info = f" - {file_stats['course_name']}" if file_stats['course_name'] else ""
                print(f"{i:2d}. {file_stats['filename']}{course_name_info}")
                print(f"     ğŸ“‚ {file_stats['path']}")
                print(f"     âŒ Hata: {file_stats['error']}")
                print()
        
        # DetaylÄ± baÅŸlÄ±k istatistikleri
        self._print_detailed_header_stats()
        
        print("=" * 80)
        print(f"â° BitiÅŸ ZamanÄ±: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("ğŸ“Š Analiz tamamlandÄ±!")
    
    def _print_detailed_header_stats(self):
        """DetaylÄ± baÅŸlÄ±k istatistiklerini yazdÄ±r"""
        print(f"\nğŸ“Š DETAYLI BAÅLIK Ä°STATÄ°STÄ°KLERÄ°:")
        print("-" * 60)
        
        # Toplam baÅŸlÄ±k sayÄ±sÄ±
        total_headers = sum(file_stats['header_count'] for file_stats in self.header_extraction_details if file_stats['has_headers'])
        total_matches = sum(file_stats['match_count'] for file_stats in self.header_extraction_details)
        
        print(f"ğŸ“‹ Toplam Ã‡Ä±karÄ±lan BaÅŸlÄ±k SayÄ±sÄ±: {total_headers}")
        print(f"ğŸ¯ Toplam EÅŸleÅŸen BaÅŸlÄ±k SayÄ±sÄ±: {total_matches}")
        
        if total_headers > 0:
            overall_match_rate = (total_matches / total_headers) * 100
            print(f"ğŸ“ˆ Genel BaÅŸlÄ±k EÅŸleÅŸme OranÄ±: {overall_match_rate:.1f}%")
        
        # En Ã§ok bulunan baÅŸlÄ±klar
        header_frequency = {}
        for file_stats in self.header_extraction_details:
            if file_stats['has_headers']:
                # KazanÄ±m tablosundan baÅŸlÄ±k isimlerini Ã§Ä±kar (bu bilgi ÅŸu an mevcut deÄŸil, opsiyonel)
                pass
        
        print(f"âš¡ Ortalama Dosya BaÅŸÄ±na BaÅŸlÄ±k: {total_headers/max(self.files_with_headers,1):.1f}")
        print(f"âš¡ Ortalama Dosya BaÅŸÄ±na EÅŸleÅŸme: {total_matches/max(self.processed_files,1):.1f}")

def main():
    """Ana iÅŸlev"""
    print("ğŸ” DBF Dosya Ä°ÅŸleme Ä°statistik Analizi BaÅŸlatÄ±lÄ±yor...")
    print("ğŸ“‹ Dosya bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ kontrolÃ¼ yapÄ±lÄ±yor...")
    
    # TÃ¼m dosyalarÄ± bul (dosya bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ kontrolÃ¼ ile)
    all_files = komutlar(validate_files=True)
    
    if not all_files:
        print("âŒ HATA: data/dbf dizininde hiÃ§ PDF/DOCX dosyasÄ± bulunamadÄ±.")
        sys.exit(1)
    
    # Ä°statistik nesnesini oluÅŸtur
    stats = DBFProcessingStats()
    stats.total_files = len(all_files)
    
    # Ä°ÅŸleme baÅŸla
    stats.start_processing()
    
    # Her dosyayÄ± iÅŸle
    for file_path in all_files:
        stats.process_file(file_path)
    
    # Ä°ÅŸlemi tamamla ve raporu yazdÄ±r
    stats.finish_processing()

if __name__ == "__main__":
    main()