"""
modules/utils_file_management.py - Dosya ƒ∞≈ülemleri Mod√ºl√º

Bu mod√ºl dosya indirme, ar≈üiv i≈ülemleri, duplicate y√∂netimi ve
ortak alan dosya sistemi i≈ülemlerini i√ßerir.

"""

import os
import shutil
import requests
import zipfile
import tempfile
from typing import List, Dict, Optional
try:
    from .utils_normalize import sanitize_filename_tr
except ImportError:
    from utils_normalize import sanitize_filename_tr


def extract_archive(archive_path: str, extract_to: str):
    """
    RAR veya ZIP ar≈üivini a√ßar.
    
    Args:
        archive_path: Ar≈üiv dosyasƒ±nƒ±n yolu
        extract_to: √áƒ±karƒ±lacak klas√∂r
    """
    if not os.path.exists(archive_path):
        raise FileNotFoundError(f"Ar≈üiv dosyasƒ± bulunamadƒ±: {archive_path}")
    
    os.makedirs(extract_to, exist_ok=True)
    
    if archive_path.lower().endswith('.zip'):
        with zipfile.ZipFile(archive_path, 'r') as zip_ref:
            zip_ref.extractall(extract_to)
            print(f"üì¶ ZIP a√ßƒ±ldƒ±: {archive_path}")
    elif archive_path.lower().endswith('.rar'):
        # RAR desteƒüi i√ßin rarfile k√ºt√ºphanesi gerekir
        try:
            import rarfile
            with rarfile.RarFile(archive_path) as rar_ref:
                rar_ref.extractall(extract_to)
                print(f"üì¶ RAR a√ßƒ±ldƒ±: {archive_path}")
        except ImportError:
            print(f"‚ö†Ô∏è RAR desteƒüi yok, rarfile k√ºt√ºphanesi gerekir: {archive_path}")
            raise
    else:
        raise ValueError(f"Desteklenmeyen ar≈üiv formatƒ±: {archive_path}")


def check_existing_file_in_all_areas(filename: str, cache_type: str, current_folder: str) -> Optional[str]:
    """
    Dosyanƒ±n diƒüer alan klas√∂rlerinde olup olmadƒ±ƒüƒ±nƒ± kontrol eder.
    
    Args:
        filename: Aranacak dosya adƒ±
        cache_type: Cache tipi (cop, dbf, dm, bom)
        current_folder: ≈ûu anki klas√∂r (dahil edilmez)
        
    Returns:
        Bulunan dosyanƒ±n tam yolu veya None
    """
    cache_root = os.path.join("data", cache_type)
    if not os.path.exists(cache_root):
        return None
    
    for item in os.listdir(cache_root):
        item_path = os.path.join(cache_root, item)
        if not os.path.isdir(item_path) or item == current_folder:
            continue
            
        file_path = os.path.join(item_path, filename)
        if os.path.exists(file_path):
            return file_path
    
    return None


def move_file_to_shared_folder(source_path: str, cache_type: str, filename: str) -> Optional[str]:
    """
    Duplicate dosyayƒ± ortak alana ta≈üƒ±r.
    NOT: 00_Ortak_Alan_Dersleri sistemi kaldƒ±rƒ±ldƒ±.
    
    Args:
        source_path: Kaynak dosya yolu
        cache_type: Cache tipi
        filename: Dosya adƒ±
    
    Returns:
        Ta≈üƒ±nan dosyanƒ±n yeni yolu veya None
    """
    try:
        # 00_Ortak_Alan_Dersleri sistemi kaldƒ±rƒ±ldƒ± - dosyalar kendi klas√∂rlerinde kalƒ±r
        print(f"üîÑ Duplicate dosya tespit edildi ancak ta≈üƒ±nmayacak: {filename}")
        return None  # Shared folder sistemi kaldƒ±rƒ±ldƒ±
        
    except Exception as e:
        print(f"‚ùå Dosya ta≈üƒ±ma hatasƒ± ({filename}): {e}")
        return None


def download_and_cache_pdf(url: str, cache_type: str, alan_adi: str = None, additional_info: str = None, alan_id: str = None, alan_db_id: int = None, meb_alan_id: str = None) -> Optional[str]:
    """
    PDF'yi indirir ve organize ≈üekilde cache'ler.
    Duplicate dosyalar i√ßin ortak alan klas√∂r√º kullanƒ±r.
    
    Args:
        url: PDF URL'si
        cache_type: 'cop', 'dbf', 'dm', 'bom' gibi dosya tipi
        alan_adi: Alan adƒ± (klas√∂r adƒ± i√ßin)
        additional_info: Ek bilgi (sƒ±nƒ±f, dal vb.)
        alan_id: Alan ID'si (organizasyon i√ßin, opsiyonel)
        alan_db_id: Veritabanƒ± alan ID'si (klas√∂r yapƒ±sƒ± i√ßin)
        meb_alan_id: MEB alan ID'si (02, 08 gibi - klas√∂r yapƒ±sƒ± i√ßin)
    
    Returns:
        ƒ∞ndirilen dosyanƒ±n yolu veya None
    """
    if not url or not cache_type:
        return None
    
    try:
        # Alan adƒ± yoksa, URL'den bir par√ßa alarak ge√ßici bir isim olu≈ütur
        if not alan_adi:
            safe_alan_adi = url.split('/')[-2] if len(url.split('/')) > 1 else "bilinmeyen_alan"
        else:
            # Merkezi sanitize fonksiyonunu kullan
            safe_alan_adi = sanitize_filename_tr(alan_adi)
        
        # Klas√∂r yapƒ±sƒ± belirleme
        if meb_alan_id and cache_type in ['cop', 'dbf', 'dm', 'bom']:
            # MEB ID bazlƒ± organizasyon: {meb_alan_id}_{alan_adi}
            folder_name = f"{meb_alan_id}_{safe_alan_adi}"
        elif alan_db_id and cache_type in ['cop', 'dbf', 'dm', 'bom']:
            # DB ID bazlƒ± organizasyon: {ID:02d}_{alan_adi}
            folder_name = f"{int(alan_db_id):02d}_{safe_alan_adi}"
        else:
            # Eski format: {alan_adi}
            folder_name = safe_alan_adi
            
        cache_dir = os.path.join("data", cache_type, folder_name)
        os.makedirs(cache_dir, exist_ok=True)
        
        # Dosya adƒ±nƒ± URL'den √ßƒ±kar
        filename = url.split('/')[-1]
        if not filename.lower().endswith(('.pdf', '.rar', '.zip')):
            filename += '.pdf' # Varsayƒ±lan
        
        # Ek bilgi varsa dosya adƒ±na ekle
        if additional_info:
            name_part, ext = os.path.splitext(filename)
            filename = f"{name_part}_{additional_info}{ext}"
        
        file_path = os.path.join(cache_dir, filename)
        
        # Dosya zaten varsa indirme
        if os.path.exists(file_path):
            print(f"üìÅ Cache'den alƒ±nƒ±yor: {file_path}")
            return file_path
        
        # Dosyanƒ±n ba≈üka alan klas√∂rlerinde olup olmadƒ±ƒüƒ±nƒ± kontrol et
        existing_file_path = check_existing_file_in_all_areas(filename, cache_type, folder_name)
        if existing_file_path:
            # Dosya ba≈üka bir alanda mevcut - ortak alana ta≈üƒ±
            shared_path = move_file_to_shared_folder(existing_file_path, cache_type, filename)
            if shared_path:
                print(f"üìÅ Ortak alandan kullanƒ±lƒ±yor: {shared_path}")
                return shared_path
        
        # 00_Ortak_Alan_Dersleri sistemi kaldƒ±rƒ±ldƒ± - bu kontrol artƒ±k yapƒ±lmƒ±yor
        
        # PDF'yi indir
        print(f"‚¨áÔ∏è ƒ∞ndiriliyor: {url}")
        response = requests.get(url, timeout=30)
        response.raise_for_status()
        
        # Dosyayƒ± kaydet
        with open(file_path, 'wb') as f:
            f.write(response.content)
        
        print(f"‚úÖ ƒ∞ndirildi: {file_path}")
        return file_path
        
    except requests.RequestException as e:
        print(f"‚ùå ƒ∞ndirme hatasƒ± ({url}): {e}")
        return None
    except Exception as e:
        print(f"‚ùå Genel hata ({url}): {e}")
        return None


def check_duplicate_files_in_cache(cache_type: str = 'cop') -> Dict:
    """
    Cache klas√∂rlerindaki duplicate dosyalarƒ± kontrol eder.
    Ortak alan sistemi kaldƒ±rƒ±ldƒ±ƒüƒ± i√ßin sadece bilgi ama√ßlƒ±.
    
    Args:
        cache_type: 'cop', 'dbf', 'dm', 'bom' gibi dosya tipi
    
    Returns:
        Dict: Duplicate dosya bilgileri
    """
    cache_root = os.path.join("data", cache_type)
    if not os.path.exists(cache_root):
        return {"error": f"Cache dizini bulunamadƒ±: {cache_root}"}
    
    # Dosya analizi
    files_by_name = {}
    folder_stats = {}
    
    for item in os.listdir(cache_root):
        item_path = os.path.join(cache_root, item)
        if not os.path.isdir(item_path):
            continue
        
        folder_name = item
        files = [f for f in os.listdir(item_path) if f.lower().endswith(('.pdf', '.rar', '.zip'))]
        folder_stats[folder_name] = len(files)
        
        # Dosya adlarƒ±nƒ± kaydet
        if folder_name not in files_by_name:
            files_by_name[folder_name] = {}
        
        for file in files:
            files_by_name[folder_name][file] = True
        
        # 00_Ortak_Alan_Dersleri sistemi kaldƒ±rƒ±ldƒ±
        # Duplicate dosyalar artƒ±k sadece log ile takip edilir
        duplicate_count = 0
        for file in files:
            if any(file in files_by_name.get(other_folder, {}) for other_folder in files_by_name if other_folder != folder_name):
                duplicate_count += 1
        
        if duplicate_count > 0:
            print(f"      üîÑ Duplicate tespit edildi: {duplicate_count} dosya (artƒ±k ta≈üƒ±nmƒ±yor)")
    
    return {
        "folder_stats": folder_stats,
        "shared_folders": []  # Ortak klas√∂r sistemi kaldƒ±rƒ±ldƒ±
    }


def scan_directory_for_pdfs(root_dir: str) -> List[Dict]:
    """
    Belirtilen dizin altƒ±ndaki t√ºm PDF dosyalarƒ±nƒ± tarar.
    
    Args:
        root_dir: Taranacak k√∂k dizin
        
    Returns:
        List[Dict]: PDF dosya bilgileri
    """
    pdfs = []
    
    if not os.path.exists(root_dir):
        return pdfs
    
    for root, dirs, files in os.walk(root_dir):
        for file in files:
            if file.lower().endswith('.pdf'):
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, root_dir)
                
                pdfs.append({
                    "path": file_path,
                    "name": file,
                    "relative_path": relative_path
                })
    
    return pdfs


def scan_directory_for_archives(root_dir: str) -> List[Dict]:
    """
    Belirtilen dizin altƒ±ndaki t√ºm ar≈üiv dosyalarƒ±nƒ± (RAR, ZIP) tarar.
    
    Args:
        root_dir: Taranacak k√∂k dizin
        
    Returns:
        List[Dict]: Ar≈üiv dosya bilgileri
    """
    archives = []
    
    if not os.path.exists(root_dir):
        return archives
    
    for root, dirs, files in os.walk(root_dir):
        for file in files:
            if file.lower().endswith(('.rar', '.zip')):
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path, root_dir)
                
                archives.append({
                    "path": file_path,
                    "name": file,
                    "relative_path": relative_path
                })
    
    return archives

def log_duplicate_files_info(cache_type: str = 'cop'):
    """
    Duplicate dosyalarƒ± konsola loglar. 
    00_Ortak_Alan_Dersleri sistemi kaldƒ±rƒ±ldƒ±, sadece bilgi ama√ßlƒ±.
    
    Args:
        cache_type: 'cop', 'dbf', 'dm', 'bom' gibi dosya tipi
    """
    cache_root = os.path.join("data", cache_type)
    if not os.path.exists(cache_root):
        print(f"Cache dizini bulunamadƒ±: {cache_root}")
        return
    
    # Dosya adƒ± -> klas√∂r listesi mapping
    file_locations = {}
    
    for item in os.listdir(cache_root):
        item_path = os.path.join(cache_root, item)
        if not os.path.isdir(item_path) or item.startswith('00_'):
            continue
            
        for file in os.listdir(item_path):
            if file.lower().endswith(('.pdf', '.rar', '.zip')):
                if file not in file_locations:
                    file_locations[file] = []
                file_locations[file].append(item)
    
    # Duplicate dosyalarƒ± listele
    duplicates = {file: locations for file, locations in file_locations.items() if len(locations) > 1}
    
    if duplicates:
        print(f"\nüîÑ {cache_type.upper()} duplicate dosyalar tespit edildi:")
        for file, locations in duplicates.items():
            print(f"  üìÑ {file} -> {len(locations)} klas√∂rde: {', '.join(locations)}")
    else:
        print(f"\n‚úÖ {cache_type.upper()} duplicate dosya bulunamadƒ±")