import os
import requests
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed
import re
from .utils_normalize import normalize_to_title_case_tr, sanitize_filename_tr
from .utils_database import with_database, get_or_create_alan, get_meb_alan_id_with_fallback, get_folder_name_for_download, get_meb_alan_ids_cached

BASE_DBF_URL = "https://meslek.meb.gov.tr/dbfgoster.aspx"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Referer": "https://meslek.meb.gov.tr/"
}

DBF_ROOT_DIR = "data/dbf"

@with_database
def get_areas_from_db_with_meb_id(cursor):
    """
    VeritabanÄ±ndan alan ID, adÄ± ve MEB ID'sini Ã§eker.
    Returns: dict {alan_adi: {'id': alan_id, 'meb_alan_id': meb_alan_id}}
    """
    try:
        cursor.execute("SELECT id, alan_adi, meb_alan_id FROM temel_plan_alan ORDER BY alan_adi")
        results = cursor.fetchall()
        return {alan_adi: {'id': area_id, 'meb_alan_id': meb_alan_id} for area_id, alan_adi, meb_alan_id in results}
    except Exception as e:
        print(f"VeritabanÄ± okuma hatasÄ±: {e}")
        return {}

@with_database
def get_areas_from_db(cursor):
    """
    VeritabanÄ±ndan alan ID ve adlarÄ±nÄ± Ã§eker.
    Returns: dict {alan_adi: alan_id}
    """
    try:
        cursor.execute("SELECT id, alan_adi FROM temel_plan_alan ORDER BY alan_adi")
        results = cursor.fetchall()
        return {alan_adi: alan_id for alan_id, alan_adi in results}
    except Exception as e:
        print(f"VeritabanÄ± okuma hatasÄ±: {e}")
        return {}


def find_matching_area_id(html_area_name, db_areas):
    """
    HTML'den gelen alan adÄ±nÄ± veritabanÄ±ndaki alanlarla eÅŸleÅŸtirir.
    Protokol alanlarÄ± iÃ§in Ã¶ncelik mantÄ±ÄŸÄ± vardÄ±r.
    Returns: (alan_id, matched_name) veya (None, None)
    """
    normalized_html_name = normalize_to_title_case_tr(html_area_name)
    
    # Tam eÅŸleÅŸme kontrolÃ¼
    if normalized_html_name in db_areas:
        return db_areas[normalized_html_name], normalized_html_name
    
    # Protokol alan kontrolÃ¼ - Ã¶nce protokol eÅŸleÅŸmelerini ara
    is_protocol_search = "- Protokol" in normalized_html_name or "protokol" in normalized_html_name.lower()
    
    if is_protocol_search:
        # Protokol alanÄ± arÄ±yoruz - Ã¶nce protokol eÅŸleÅŸmelerini kontrol et
        for db_name, area_id in db_areas.items():
            if "- Protokol" in db_name and (normalized_html_name.lower() in db_name.lower() or db_name.lower() in normalized_html_name.lower()):
                print(f"Protokol eÅŸleÅŸme bulundu: '{html_area_name}' -> '{db_name}' (ID: {area_id})")
                return area_id, db_name
    else:
        # Normal alan arÄ±yoruz - Ã¶nce protokol olmayan eÅŸleÅŸmeleri kontrol et  
        for db_name, area_id in db_areas.items():
            if "- Protokol" not in db_name and (normalized_html_name.lower() in db_name.lower() or db_name.lower() in normalized_html_name.lower()):
                print(f"Normal eÅŸleÅŸme bulundu: '{html_area_name}' -> '{db_name}' (ID: {area_id})")
                return area_id, db_name
    
    # Genel kÄ±smi eÅŸleÅŸme kontrolÃ¼ (eski mantÄ±k - fallback)
    for db_name, area_id in db_areas.items():
        if normalized_html_name.lower() in db_name.lower() or db_name.lower() in normalized_html_name.lower():
            print(f"Genel eÅŸleÅŸme bulundu: '{html_area_name}' -> '{db_name}' (ID: {area_id})")
            return area_id, db_name
    
    print(f"EÅŸleÅŸme bulunamadÄ±: '{html_area_name}' (normalize: '{normalized_html_name}')")
    return None, None

def get_dbf_data_for_alan_and_sinif(alan_adi, meb_alan_id, sinif_kodu):
    """
    Belirli bir alan ve sÄ±nÄ±f iÃ§in DBF verilerini Ã§eker.
    Hem normal hem protokol dosyalarÄ±nÄ± tespit eder (dosya adÄ±ndan).
    """
    params = {"kurum_id": "1", "sinif_kodu": sinif_kodu, "alan_id": meb_alan_id}
    
    try:
        response = requests.get(BASE_DBF_URL, params=params, headers=HEADERS, timeout=15)
        response.raise_for_status()
        response.encoding = response.apparent_encoding
        soup = BeautifulSoup(response.text, "html.parser")

        # DBF linklerini bul (RAR/ZIP dosyasÄ±)
        dbf_links = soup.find_all('a', href=lambda x: x and (x.endswith('.rar') or x.endswith('.zip')))
        
        found_files = {}  # {alan_type: data}
        
        if dbf_links:
            for link in dbf_links:
                href = link.get('href', '')
                if href:
                    # Bozuk URL'leri filtrele (cop9/upload iÃ§eren linkler)
                    if '/cop9/upload/' in href:
                        print(f"ğŸš« Bozuk URL atlandÄ±: {href}")
                        continue
                    
                    # Tam URL'yi oluÅŸtur
                    if href.startswith('http'):
                        dbf_url = href
                    else:
                        dbf_url = requests.compat.urljoin(response.url, href)
                    
                    # Dosya adÄ±ndan protokol tespiti yap
                    filename = href.split('/')[-1].lower()
                    is_protokol = any(x in filename for x in ['pro', 'protokol'])
                    
                    # Tarih bilgisini bul
                    tarih = ""
                    parent_div = link.find_parent('div')
                    if parent_div:
                        for li in parent_div.find_all('li'):
                            if 'calendar' in str(li) or re.search(r'\d{2}\.\d{2}\.\d{4}', li.get_text()):
                                tarih = li.get_text(strip=True)
                                break
                    
                    # GÃ¼ncelleme yÄ±lÄ±nÄ± Ã§Ä±kar
                    update_year = None
                    if tarih:
                        year_match = re.search(r'(\d{4})', tarih)
                        if year_match:
                            year = int(year_match.group(1))
                            if 2000 <= year <= 2030:
                                update_year = str(year)
                    
                    # Alan tipini belirle
                    if is_protokol:
                        file_alan_adi = f"{alan_adi} - Protokol" if not alan_adi.endswith(" - Protokol") else alan_adi
                    else:
                        file_alan_adi = alan_adi.replace(" - Protokol", "") if " - Protokol" in alan_adi else alan_adi
                    
                    # Ä°lk geÃ§erli URL'yi kullan (daha Ã¶nceden bu alan iÃ§in URL kaydedilmemiÅŸse)
                    if file_alan_adi not in found_files:
                        found_files[file_alan_adi] = {
                            "link": dbf_url,
                            "guncelleme_tarihi": tarih,
                            "update_year": update_year,
                            "meb_alan_id": meb_alan_id,
                            "filename": filename,
                            "is_protokol": is_protokol
                        }
                        
                        print(f"ğŸ“‹ DBF Dosya tespit edildi: {file_alan_adi} -> {filename} {'(Protokol)' if is_protokol else '(Normal)'}")
        
        # Ã‡aÄŸÄ±ran tarafÄ±n istediÄŸi alan tipini dÃ¶ndÃ¼r
        return found_files.get(alan_adi)
        
    except requests.RequestException as e:
        print(f"DBF Hata: {alan_adi} ({sinif_kodu}. sÄ±nÄ±f) sayfasÄ± Ã§ekilemedi: {e}")
        return None

def get_all_dbf_files_for_alan_and_sinif(alan_adi, meb_alan_id, sinif_kodu):
    """
    Belirli bir MEB alan ID ve sÄ±nÄ±f iÃ§in tÃ¼m DBF dosyalarÄ±nÄ± (normal + protokol) Ã§eker.
    """
    params = {"kurum_id": "1", "sinif_kodu": sinif_kodu, "alan_id": meb_alan_id}
    
    try:
        response = requests.get(BASE_DBF_URL, params=params, headers=HEADERS, timeout=15)
        response.raise_for_status()
        response.encoding = response.apparent_encoding
        soup = BeautifulSoup(response.text, "html.parser")

        # DBF linklerini bul (RAR/ZIP dosyasÄ±)
        dbf_links = soup.find_all('a', href=lambda x: x and (x.endswith('.rar') or x.endswith('.zip')))
        
        found_files = []  # [{"alan_adi": ..., "data": ...}]
        
        if dbf_links:
            # TÃ¼m linkleri topla ve URL kalitesine gÃ¶re sÄ±rala
            all_links = []
            for link in dbf_links:
                href = link.get('href', '')
                if href:
                    # Tam URL'yi oluÅŸtur
                    if href.startswith('http'):
                        dbf_url = href
                    else:
                        dbf_url = requests.compat.urljoin(response.url, href)
                    
                    # Bozuk URL'leri filtrele (cop9/upload iÃ§eren linkler)
                    if '/cop9/upload/' in href:
                        print(f"ğŸš« Bozuk URL atlandÄ±: {href}")
                        continue
                    
                    # URL kalitesi kontrolÃ¼ - doÄŸru pattern olmalÄ± (upload/dbf{grade}/)
                    url_quality = 0
                    if f'/upload/dbf{sinif_kodu}/' in href:
                        url_quality = 10  # En iyi - doÄŸru pattern
                    elif '/upload/' in href and 'dbf' in href:
                        url_quality = 5   # Orta - upload var ama pattern tam deÄŸil
                    elif not ('cop' in href and 'upload' in href):
                        url_quality = 1   # DÃ¼ÅŸÃ¼k - bozuk pattern deÄŸil ama ideal deÄŸil
                    else:
                        continue  # Bozuk pattern, atla
                    
                    # Dosya adÄ±ndan protokol tespiti yap
                    filename = href.split('/')[-1].lower()
                    is_protokol = any(x in filename for x in ['pro', 'protokol'])
                    
                    # Tarih bilgisini bul
                    tarih = ""
                    parent_div = link.find_parent('div')
                    if parent_div:
                        for li in parent_div.find_all('li'):
                            if 'calendar' in str(li) or re.search(r'\d{2}\.\d{2}\.\d{4}', li.get_text()):
                                tarih = li.get_text(strip=True)
                                break
                    
                    # GÃ¼ncelleme yÄ±lÄ±nÄ± Ã§Ä±kar
                    update_year = None
                    if tarih:
                        year_match = re.search(r'(\d{4})', tarih)
                        if year_match:
                            year = int(year_match.group(1))
                            if 2000 <= year <= 2030:
                                update_year = str(year)
                    
                    # Alan adÄ±nÄ± belirle
                    if is_protokol:
                        file_alan_adi = f"{alan_adi} - Protokol"
                    else:
                        file_alan_adi = alan_adi
                    
                    all_links.append({
                        "alan_adi": file_alan_adi,
                        "link": dbf_url,
                        "guncelleme_tarihi": tarih,
                        "update_year": update_year,
                        "meb_alan_id": meb_alan_id,
                        "filename": filename,
                        "is_protokol": is_protokol,
                        "url_quality": url_quality,
                        "href": href
                    })
            
            # En kaliteli linkleri seÃ§ (alan adÄ±na gÃ¶re grupla ve en iyi kaliteli olanÄ± al)
            found_files_dict = {}
            for link_data in sorted(all_links, key=lambda x: x["url_quality"], reverse=True):
                alan_adi_key = link_data["alan_adi"]
                
                # EÄŸer bu alan iÃ§in daha iyi bir link yoksa, bu linki kullan
                if alan_adi_key not in found_files_dict or found_files_dict[alan_adi_key]["url_quality"] < link_data["url_quality"]:
                    found_files_dict[alan_adi_key] = {
                        "link": link_data["link"],
                        "guncelleme_tarihi": link_data["guncelleme_tarihi"],
                        "update_year": link_data["update_year"],
                        "meb_alan_id": link_data["meb_alan_id"],
                        "filename": link_data["filename"],
                        "is_protokol": link_data["is_protokol"],
                        "url_quality": link_data["url_quality"]
                    }
                    
                    quality_text = "âœ… EN Ä°YÄ°" if link_data["url_quality"] == 10 else "âš ï¸ ORTA" if link_data["url_quality"] == 5 else "â“ DÃœÅÃœK"
                    print(f"ğŸ“‹ DBF Dosya tespit edildi: {alan_adi_key} -> {link_data['filename']} {'(Protokol)' if link_data['is_protokol'] else '(Normal)'} [{quality_text}]")
            
            # Convert to required format
            for alan_adi_key, data in found_files_dict.items():
                found_files.append({
                    "alan_adi": alan_adi_key,
                    "data": data
                })
        
        return found_files
        
    except requests.RequestException as e:
        print(f"DBF Hata: {alan_adi} ({sinif_kodu}. sÄ±nÄ±f) sayfasÄ± Ã§ekilemedi: {e}")
        return []

def get_dbf_data(siniflar=["9", "10", "11", "12"]):
    """
    TÃ¼m sÄ±nÄ±flar iÃ§in DBF (Ders Bilgi Formu) verilerini eÅŸzamanlÄ± olarak Ã§eker.
    Her MEB alan ID sayfasÄ±ndan hem normal hem protokol dosyalarÄ±nÄ± tespit eder.
    """
    # Ã–nce MEB alan ID'lerini Ã§ek (cache'den)
    print("ğŸ“‹ MEB Alan ID'leri Ã§ekiliyor...")
    meb_alan_ids = get_meb_alan_ids_cached()
    
    if not meb_alan_ids:
        print("âŒ MEB Alan ID'leri Ã§ekilemedi!")
        return {}
    
    print(f"ğŸ” {len(meb_alan_ids)} alan iÃ§in DBF linkleri Ã§ekiliyor (akÄ±llÄ± tespit)...")
    
    # TÃ¼m alan+sÄ±nÄ±f kombinasyonlarÄ± iÃ§in task listesi oluÅŸtur (sadece temel alanlar)
    tasks = []
    for alan_adi, meb_alan_id in meb_alan_ids.items():
        for sinif in siniflar:
            tasks.append((alan_adi, meb_alan_id, sinif))
    
    # SonuÃ§larÄ± organize et
    all_dbf_data = {}
    
    # Paralel iÅŸleme
    with ThreadPoolExecutor(max_workers=len(siniflar)) as executor:
        # Future'larÄ± submit et
        future_to_task = {
            executor.submit(get_all_dbf_files_for_alan_and_sinif, alan_adi, meb_alan_id, sinif): (alan_adi, meb_alan_id, sinif)
            for alan_adi, meb_alan_id, sinif in tasks
        }
        
        # SonuÃ§larÄ± topla
        for future in as_completed(future_to_task):
            base_alan_adi, meb_alan_id, sinif = future_to_task[future]
            
            try:
                found_files = future.result()
                
                if found_files:
                    # SÄ±nÄ±f bazÄ±nda organize et
                    if sinif not in all_dbf_data:
                        all_dbf_data[sinif] = {}
                    
                    # Her bulunan dosyayÄ± ekle
                    for file_info in found_files:
                        alan_adi = file_info["alan_adi"]
                        dbf_data = file_info["data"]
                        
                        all_dbf_data[sinif][alan_adi] = dbf_data
                        
                        if dbf_data["is_protokol"]:
                            print(f"âœ… {alan_adi} ({sinif}. sÄ±nÄ±f) -> DBF bulundu (Protokol, ID: {meb_alan_id})")
                        else:
                            print(f"âœ… {alan_adi} ({sinif}. sÄ±nÄ±f) -> DBF bulundu (Normal, ID: {meb_alan_id})")
                else:
                    print(f"âŒ {base_alan_adi} ({sinif}. sÄ±nÄ±f) -> DBF bulunamadÄ±")
                    
            except Exception as e:
                print(f"âŒ {base_alan_adi} ({sinif}. sÄ±nÄ±f) DBF iÅŸleme hatasÄ±: {e}")
    
    return all_dbf_data


def sanitize_filename(name):
    """
    Dosya/klasÃ¶r ismi olarak kullanÄ±labilir hale getir.
    utils.py'deki merkezi sanitize_filename_tr fonksiyonunu kullanÄ±r.
    """
    return sanitize_filename_tr(name)

def get_or_create_area_for_download(cursor, alan_adi, meb_alan_ids=None):
    """
    Ä°ndirme iÅŸlemi iÃ§in alan ID'sini alÄ±r veya oluÅŸturur.
    
    Args:
        cursor: Database cursor
        alan_adi: Alan adÄ±
        meb_alan_ids: MEB alan ID'leri dict'i (opsiyonel)
    
    Returns:
        tuple: (alan_id, meb_alan_id, matched_name)
    """
    # Ã–nce mevcut alanlarÄ± kontrol et
    db_areas = get_areas_from_db()
    area_id, matched_name = find_matching_area_id(alan_adi, db_areas)
    
    if area_id:
        # Alan bulundu, MEB ID'sini al
        db_areas_with_meb = get_areas_from_db_with_meb_id()
        meb_alan_id = db_areas_with_meb.get(matched_name, {}).get('meb_alan_id')
        return area_id, meb_alan_id, matched_name
    
    # Alan bulunamadÄ±, oluÅŸtur
    print(f"ğŸ†• Yeni alan oluÅŸturuluyor: {alan_adi}")
    
    # MEB Alan ID'sini al
    meb_alan_id = None
    if meb_alan_ids:
        meb_alan_id = meb_alan_ids.get(alan_adi)
    
    # Alan oluÅŸtur
    alan_id = get_or_create_alan(cursor, alan_adi, meb_alan_id=meb_alan_id)
       
    return alan_id, meb_alan_id, alan_adi

# Bu fonksiyon kaldÄ±rÄ±ldÄ± - unrar iÅŸlemleri artÄ±k yapÄ±lmÄ±yor
# Sadece get_dbf() fonksiyonu kullanÄ±lacak (indirme + URL kaydetme)

@with_database
def get_dbf(cursor, dbf_data=None):
    """
    DBF (Ders Bilgi Formu) linklerini Ã§eker ve iÅŸler.
    HTML parsing ile yeni alanlarÄ± kontrol eder.
    URL'leri JSON formatÄ±nda gruplar ve veritabanÄ±na kaydeder.
    RAR/ZIP dosyalarÄ±nÄ± indirir (aÃ§maz).
    data/get_dbf.json Ã§Ä±ktÄ± dosyasÄ± Ã¼retir.
    Progress mesajlarÄ± yield eder.
    """
    if not os.path.exists(DBF_ROOT_DIR):
        os.makedirs(DBF_ROOT_DIR)

    # DBF verilerini Ã§ek (eÄŸer geÃ§ilmemiÅŸse)
    if dbf_data is None:
        yield {'type': 'status', 'message': 'DBF linkleri Ã§ekiliyor...'}
        dbf_data = get_dbf_data()
        if not dbf_data:
            yield {'type': 'error', 'message': 'DBF verileri Ã§ekilemedi!'}
            return

    # MEB alan ID'lerini al (cache'den)
    meb_alan_ids = get_meb_alan_ids_cached()

    for sinif, alanlar in dbf_data.items():
        for alan_adi, info in alanlar.items():
            link = info["link"]
            is_protokol = info.get("is_protokol", False)
            
            try:
                # MEB ID'yi Ã§oklu kaynak stratejisi ile al
                data_meb_id = info.get("meb_alan_id")
                meb_alan_id, source = get_meb_alan_id_with_fallback(alan_adi, data_meb_id)
                
                # Alan ID'sini al veya oluÅŸtur - protokol durumunu kontrol et
                # Protokol dosyalar iÃ§in protokol alan adÄ±nÄ± kullan
                search_alan_adi = alan_adi
                if is_protokol and not alan_adi.endswith("- Protokol"):
                    search_alan_adi = f"{alan_adi} - Protokol"
                
                area_id, _, matched_name = get_or_create_area_for_download(cursor, search_alan_adi, meb_alan_ids)
                
                # KlasÃ¶r adÄ±nÄ± yeni strateji ile belirle
                folder_name = get_folder_name_for_download(matched_name or search_alan_adi, meb_alan_id, area_id)
                alan_dir = os.path.join(DBF_ROOT_DIR, folder_name)
                
                if meb_alan_id:
                    yield {"type": "status", "message": f"[{alan_adi}] KlasÃ¶r: {folder_name} (MEB ID: {meb_alan_id}, kaynak: {source})"}
                else:
                    yield {"type": "warning", "message": f"[{alan_adi}] MEB ID bulunamadÄ±, alan adÄ± kullanÄ±lÄ±yor: {folder_name}"}
                
            except Exception as e:
                # Hata durumunda eski sistemi kullan
                alan_dir = os.path.join(DBF_ROOT_DIR, sanitize_filename(alan_adi))
                yield {"type": "error", "message": f"[{alan_adi}] Alan iÅŸleme hatasÄ±: {e}, eski format kullanÄ±lÄ±yor"}
            
            if not os.path.exists(alan_dir):
                os.makedirs(alan_dir)
            archive_filename = os.path.basename(link)
            archive_path = os.path.join(alan_dir, archive_filename)

            # Dosya zaten varsa atla
            if os.path.exists(archive_path):
                file_size = os.path.getsize(archive_path)
                yield {"type": "info", "message": f"ğŸ“ {alan_adi} -> {archive_filename} zaten mevcut ({file_size // (1024*1024)}MB)"}
                continue

            # Ä°ndir - hata durumunda devam et
            yield {"type": "status", "message": f"â¬‡ï¸ {alan_adi} -> {archive_filename} indiriliyor..."}
            
            try:
                # Ã–nce HEAD request ile dosya varlÄ±ÄŸÄ±nÄ± kontrol et
                head_response = requests.head(link, timeout=10)
                if head_response.status_code == 404:
                    yield {"type": "warning", "message": f"âš ï¸ {alan_adi} -> {archive_filename} dosya bulunamadÄ± (404) - atlanÄ±yor"}
                    continue
                elif head_response.status_code >= 400:
                    yield {"type": "warning", "message": f"âš ï¸ {alan_adi} -> {archive_filename} eriÅŸim hatasÄ± ({head_response.status_code}) - atlanÄ±yor"}
                    continue
                
                # Dosya indirme
                with requests.get(link, stream=True, timeout=60) as r:
                    r.raise_for_status()
                    
                    # Content-Length header'dan dosya boyutunu al
                    total_size = int(r.headers.get('content-length', 0))
                    downloaded_size = 0
                    
                    with open(archive_path, "wb") as f:
                        for chunk in r.iter_content(chunk_size=8192):
                            if chunk:
                                f.write(chunk)
                                downloaded_size += len(chunk)
                
                # BaÅŸarÄ±lÄ± indirme
                yield {"type": "success", "message": f"ğŸ“ {alan_adi} -> {archive_filename} indirildi ({downloaded_size // (1024*1024)}MB)"}
                
            except requests.exceptions.Timeout:
                yield {"type": "error", "message": f"âŒ {alan_adi} -> {archive_filename} indirme timeout (60s) - atlanÄ±yor"}
                # YarÄ±da kalan dosyayÄ± sil
                if os.path.exists(archive_path):
                    os.remove(archive_path)
                continue
                
            except requests.exceptions.HTTPError as e:
                yield {"type": "error", "message": f"âŒ {alan_adi} -> {archive_filename} HTTP hatasÄ±: {e} - atlanÄ±yor"}
                # YarÄ±da kalan dosyayÄ± sil
                if os.path.exists(archive_path):
                    os.remove(archive_path)
                continue
                
            except requests.exceptions.RequestException as e:
                yield {"type": "error", "message": f"âŒ {alan_adi} -> {archive_filename} baÄŸlantÄ± hatasÄ±: {e} - atlanÄ±yor"}
                # YarÄ±da kalan dosyayÄ± sil
                if os.path.exists(archive_path):
                    os.remove(archive_path)
                continue
                
            except Exception as e:
                yield {"type": "error", "message": f"âŒ {alan_adi} -> {archive_filename} genel hata: {e} - atlanÄ±yor"}
                # YarÄ±da kalan dosyayÄ± sil
                if os.path.exists(archive_path):
                    os.remove(archive_path)
                continue

            # AÃ‡MA Ä°ÅLEMÄ° GEÃ‡Ä°CÄ° OLARAK KAPAT
            # msg = f"[{alan_adi}] {archive_filename} aÃ§Ä±lÄ±yor..."
            # print(msg)
            # yield {"type": "status", "message": msg}
            # try:
            #     extract_archive(archive_path, alan_dir)
            #     msg = f"[{alan_adi}] {archive_filename} baÅŸarÄ±yla aÃ§Ä±ldÄ±."
            #     print(msg)
            #     yield {"type": "status", "message": msg}
            # except Exception as e:
            #     msg = f"[{alan_adi}] {archive_filename} aÃ§Ä±lamadÄ±: {e}"
            #     print(msg)
            #     yield {"type": "error", "message": msg}

    # DBF URL'lerini JSON formatÄ±nda veritabanÄ±na kaydet
    yield {'type': 'status', 'message': 'DBF URL\'leri veritabanÄ±na kaydediliyor...'}
    try:
        # Alan bazÄ±nda URL'leri grupla
        alan_dbf_urls = {}
        for sinif, alanlar in dbf_data.items():
            for alan_adi, info in alanlar.items():
                if alan_adi not in alan_dbf_urls:
                    alan_dbf_urls[alan_adi] = {}
                alan_dbf_urls[alan_adi][str(sinif)] = info['link']
        
        # Her alan iÃ§in URL'leri JSON formatÄ±nda veritabanÄ±na kaydet
        import json
        saved_alan_count = 0
        for alan_adi, alan_urls in alan_dbf_urls.items():
            try:
                # MEB alan ID'sini al (eÄŸer varsa)
                meb_alan_id = meb_alan_ids.get(alan_adi) if meb_alan_ids else None
                
                # Alan ID'sini al veya oluÅŸtur (ORJÄ°NAL ALAN ADI ile)
                alan_id = with_database(lambda c: get_or_create_alan(c, alan_adi, meb_alan_id=meb_alan_id, dbf_urls=alan_urls))()
                                
                saved_alan_count += 1
                sÄ±nÄ±f_sayÄ±sÄ± = len(alan_urls)
                
                # Standardize edilmiÅŸ konsol Ã§Ä±ktÄ±sÄ± - alan bazlÄ± toplam
                yield {'type': 'progress', 'message': f'{meb_alan_id} - {alan_adi} ({saved_alan_count}/{len(alan_dbf_urls)}) Toplam {sÄ±nÄ±f_sayÄ±sÄ±} DBF indi.', 'progress': saved_alan_count / len(alan_dbf_urls)}
                
            except Exception as e:
                yield {'type': 'error', 'message': f'URL kaydetme hatasÄ± ({alan_adi}): {e}'}
        
        yield {'type': 'success', 'message': f'âœ… {saved_alan_count} alan iÃ§in URL\'ler veritabanÄ±na kaydedildi.'}
        
        # Merkezi istatistik fonksiyonunu kullan (CLAUDE.md kurallarÄ±)
        try:
            from .utils_stats import get_database_statistics, format_database_statistics_message
            stats = get_database_statistics()
            stats_message = format_database_statistics_message(stats)
            yield {'type': 'info', 'message': stats_message}
        except Exception as e:
            yield {'type': 'warning', 'message': f'Ä°statistik alÄ±namadÄ±: {e}'}
        
        # JSON Ã§Ä±ktÄ± dosyasÄ± oluÅŸtur
        output_filename = "data/get_dbf.json"
        try:
            with open(output_filename, 'w', encoding='utf-8') as f:
                json.dump(alan_dbf_urls, f, ensure_ascii=False, indent=2)
            yield {'type': 'success', 'message': f'DBF verileri kaydedildi: {output_filename}'}
        except Exception as e:
            yield {'type': 'error', 'message': f'JSON dosyasÄ± kaydedilemedi: {e}'}
        
    except Exception as e:
        yield {'type': 'error', 'message': f'DBF URL kaydetme hatasÄ±: {e}'}
    
    yield {'type': 'done', 'message': f'TÃ¼m DBF dosyalarÄ± iÅŸlendi. {len(alan_dbf_urls) if "alan_dbf_urls" in locals() else 0} alan iÃ§in URL\'ler veritabanÄ±na kaydedildi.'}

# Bu fonksiyon kaldÄ±rÄ±ldÄ± - unrar iÅŸlemleri artÄ±k yapÄ±lmÄ±yor
# Sadece get_dbf() fonksiyonu kullanÄ±lacak (indirme + URL kaydetme)

# Bu fonksiyon kaldÄ±rÄ±ldÄ± - unrar iÅŸlemleri artÄ±k yapÄ±lmÄ±yor

# Bu fonksiyon kaldÄ±rÄ±ldÄ± - unrar iÅŸlemleri artÄ±k yapÄ±lmÄ±yor

# Bu fonksiyon kaldÄ±rÄ±ldÄ± - unrar iÅŸlemleri artÄ±k yapÄ±lmÄ±yor

def extract_course_name_from_dbf(dbf_file_path):
    """
    DBF dosyasÄ±ndan ders adÄ±nÄ± Ã§Ä±karÄ±r
    """
    try:
        if os.path.exists(dbf_file_path) and dbf_file_path.lower().endswith(('.pdf', '.docx')):
            # extract_ders_adi importu kaldÄ±rÄ±ldÄ±, burada fonksiyon Ã§aÄŸrÄ±sÄ± eksik olabilir
            # Ancak legacy uyumluluk iÃ§in alias eklenecek
            from .oku_dbf import extract_ders_adi
            ders_adi = extract_ders_adi(dbf_file_path)
            return ders_adi.strip() if ders_adi else None
    except Exception as e:
        print(f"DBF dosyasÄ± okuma hatasÄ± ({dbf_file_path}): {e}")
    return None

# Alias for legacy compatibility
extract_ders_adi = extract_course_name_from_dbf

def match_dbf_to_course_by_content(dbf_file_path, course_name):
    """
    DBF dosya iÃ§eriÄŸinden Ã§Ä±karÄ±lan ders adÄ± ile veritabanÄ±ndaki ders adÄ±nÄ± eÅŸleÅŸtirir
    """
    extracted_course_name = extract_course_name_from_dbf(dbf_file_path)
    
    if not extracted_course_name:
        return False, 0
    
    extracted_clean = extracted_course_name.lower().strip()
    course_clean = course_name.lower().strip()
    
    # Tam eÅŸleÅŸme
    if extracted_clean == course_clean:
        return True, 100
    
    # KÄ±smi eÅŸleÅŸme
    if extracted_clean in course_clean or course_clean in extracted_clean:
        return True, 90
    
    # Kelime bazlÄ± eÅŸleÅŸme
    extracted_words = set(extracted_clean.split())
    course_words = set(course_clean.split())
    common_words = extracted_words.intersection(course_words)
    
    if len(common_words) > 0:
        similarity = (len(common_words) * 2) / (len(extracted_words) + len(course_words)) * 100
        if similarity > 70:
            return True, similarity
    
    return False, 0

def scan_dbf_files_and_extract_courses(alan_adi=None):
    """
    DBF klasÃ¶rlerini tarar ve her dosyadan ders adÄ±nÄ± Ã§Ä±karÄ±r
    """
    results = {}
    
    if not os.path.exists(DBF_ROOT_DIR):
        return results
    
    alan_klasorleri = [d for d in os.listdir(DBF_ROOT_DIR) 
                       if os.path.isdir(os.path.join(DBF_ROOT_DIR, d))]
    
    if alan_adi:
        alan_klasorleri = [alan_adi] if alan_adi in alan_klasorleri else []
    
    for alan_klasor in alan_klasorleri:
        alan_dir = os.path.join(DBF_ROOT_DIR, alan_klasor)
        results[alan_klasor] = {}
        
        # Alan klasÃ¶rÃ¼ altÄ±ndaki tÃ¼m klasÃ¶rleri ve dosyalarÄ± tara
        for root, dirs, files in os.walk(alan_dir):
            for file in files:
                if file.lower().endswith(('.pdf', '.docx')):
                    file_path = os.path.join(root, file)
                    relative_path = os.path.relpath(file_path, alan_dir)
                    
                    ders_adi = extract_course_name_from_dbf(file_path)
                    if ders_adi:
                        results[alan_klasor][relative_path] = {
                            'ders_adi': ders_adi,
                            'dosya_adi': file,
                            'tam_yol': file_path
                        }
    
    return results

@with_database
def save_dbf_urls_to_database(cursor):
    """
    DBF URL'lerini veritabanÄ±na JSON formatÄ±nda kaydeder.
    """
    import json
    
    # DBF verilerini Ã§ek
    print("ğŸ“‹ DBF linkleri Ã§ekiliyor...")
    dbf_data = get_dbf_data()
    
    if not dbf_data:
        print("âŒ DBF verileri Ã§ekilemedi!")
        return {"success": False, "error": "DBF verileri Ã§ekilemedi"}
    
    # Alan bazÄ±nda URL'leri grupla
    alan_dbf_urls = {}
    for sinif, alanlar in dbf_data.items():
        for alan_adi, info in alanlar.items():
            if alan_adi not in alan_dbf_urls:
                alan_dbf_urls[alan_adi] = {}
            alan_dbf_urls[alan_adi][str(sinif)] = info['link']
    
    print(f"ğŸ” {len(alan_dbf_urls)} alan iÃ§in URL'ler veritabanÄ±na kaydediliyor...")
    
    # MEB alan ID'lerini gÃ¼ncelle (cache'den)
    meb_alan_ids = get_meb_alan_ids_cached()
    
    saved_count = 0
    
    for alan_adi, dbf_urls in alan_dbf_urls.items():
        try:
            # MEB Alan ID'sini al
            meb_alan_id = meb_alan_ids.get(alan_adi)
            
            # JSON formatÄ±nda kaydet
            dbf_urls_json = json.dumps(dbf_urls)
            
            # Alan oluÅŸtur veya gÃ¼ncelle (otomatik oluÅŸturma)
            alan_id = get_or_create_alan(cursor, alan_adi, meb_alan_id=meb_alan_id, dbf_urls=dbf_urls_json)
                        
            saved_count += 1
            print(f"âœ… {alan_adi}: {len(dbf_urls)} sÄ±nÄ±f URL'si kaydedildi (MEB ID: {meb_alan_id})")
            
        except Exception as e:
            print(f"âŒ {alan_adi} kaydetme hatasÄ±: {e}")
            continue
        
    print(f"ğŸ¯ Toplam {saved_count} alan iÃ§in DBF URL'leri veritabanÄ±na kaydedildi!")
    return {"success": True, "count": saved_count}

def main():
    """
    DBF iÅŸlemleri ana menÃ¼sÃ¼
    """
    print("Ders Bilgi Formu (DBF) Getirici")
    print("1. Veri Ã‡ek (9, 10, 11, 12. sÄ±nÄ±flar)")
    print("2. DBF Ä°ndir (Sadece Ä°ndirme - AÃ§ma Yok)")
    print("3. DBF DosyalarÄ±ndan Ders AdlarÄ±nÄ± Ã‡Ä±kar")
    print("4. DBF URL'lerini VeritabanÄ±na Kaydet")
    
    choice = input("SeÃ§iminizi yapÄ±n (1-4): ").strip()
    
    if choice == "1":
        print("DBF verileri Ã§ekiliyor...")
        dbf_data = get_dbf_data()
        if dbf_data:
            print("âœ… DBF verileri baÅŸarÄ±yla Ã§ekildi!")
            print(f"Toplam {sum(len(alanlar) for alanlar in dbf_data.values())} alan bulundu.")
        else:
            print("âŒ DBF verileri Ã§ekilemedi!")
    
    elif choice == "2":
        print("DBF verileri Ã§ekiliyor ve indiriliyor...")
        for message in get_dbf():
            msg_type = message.get("type", "info")
            msg_text = message.get("message", "")
            
            if msg_type == "error":
                print(f"âŒ {msg_text}")
            elif msg_type == "warning":
                print(f"âš ï¸ {msg_text}")
            elif msg_type == "success":
                print(f"âœ… {msg_text}")
            elif msg_type == "done":
                print(f"ğŸ‰ {msg_text}")
                break
            else:
                print(f"â„¹ï¸ {msg_text}")
    
    elif choice == "3":
        print("DBF dosyalarÄ±ndan ders adlarÄ± Ã§Ä±karÄ±lÄ±yor...")
        results = scan_dbf_files_and_extract_courses()
        
        if not results:
            print("âŒ DBF dosyasÄ± bulunamadÄ±!")
            return
        
        toplam_dosya = 0
        basarili_dosya = 0
        
        for alan_adi, dosyalar in results.items():
            print(f"\nğŸ“ {alan_adi}:")
            for dosya_yolu, bilgi in dosyalar.items():
                toplam_dosya += 1
                if bilgi['ders_adi']:
                    basarili_dosya += 1
                    print(f"  âœ… {bilgi['dosya_adi']} â†’ {bilgi['ders_adi']}")
                else:
                    print(f"  âŒ {bilgi['dosya_adi']} â†’ Ders adÄ± Ã§Ä±karÄ±lamadÄ±")
        
        print(f"\nğŸ“Š Ã–zet: {basarili_dosya}/{toplam_dosya} dosyadan ders adÄ± Ã§Ä±karÄ±ldÄ± (%{basarili_dosya/toplam_dosya*100:.1f})")
    
    elif choice == "4":
        print("DBF URL'leri veritabanÄ±na kaydediliyor...")
        result = save_dbf_urls_to_database()
        if result and result.get("success"):
            print(f"âœ… Ä°ÅŸlem tamamlandÄ±! {result.get('count', 0)} alan kaydedildi.")
        else:
            print("âŒ Ä°ÅŸlem baÅŸarÄ±sÄ±z!")
    
    else:
        print("GeÃ§ersiz seÃ§im!")

if __name__ == "__main__":
    main()
