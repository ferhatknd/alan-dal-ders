import requests
from bs4 import BeautifulSoup
import sys

import time
BASE_OPTIONS_URL = "https://meslek.meb.gov.tr/cercevelistele.aspx"
BASE_DERS_ALT_URL = "https://meslek.meb.gov.tr/dmgoster.aspx"

# Sunucu tarafÄ±ndan engellenmemek iÃ§in bir tarayÄ±cÄ± gibi davranan baÅŸlÄ±klar ekleyelim.
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Referer": "https://meslek.meb.gov.tr/"
}

def get_alanlar(sinif_kodu="9"):
    params = {"sinif_kodu": sinif_kodu, "kurum_id": "1"}
    try:
        resp = requests.get(BASE_OPTIONS_URL, params=params, headers=HEADERS, timeout=10)
        resp.raise_for_status()  # 4xx veya 5xx HTTP durum kodlarÄ±nda hata fÄ±rlatÄ±r.
    except requests.exceptions.RequestException as e:
        return []

    resp.encoding = resp.apparent_encoding
    soup = BeautifulSoup(resp.text, "html.parser")
    sel = soup.find('select', id="ContentPlaceHolder1_drpalansec")
    if not sel:
        return []
    alanlar = []
    for opt in sel.find_all('option'):
        val = opt.get('value','').strip()
        name = opt.text.strip()
        if val and val not in ("00","0"):
            alanlar.append({"id": val, "isim": name})
    return alanlar

def get_dersler_for_alan(alan_id, alan_adi, sinif_kodu="9"):
    params = {"sinif_kodu": sinif_kodu, "kurum_id": "1", "alan_id": alan_id}
    try:
        resp = requests.get(BASE_DERS_ALT_URL, params=params, headers=HEADERS, timeout=10)
        resp.raise_for_status() # 4xx veya 5xx HTTP durum kodlarÄ±nda hata fÄ±rlatÄ±r.
    except requests.exceptions.RequestException as e:
        return []

    resp.encoding = resp.apparent_encoding
    soup = BeautifulSoup(resp.text, "html.parser")

    dersler = []
    for div in soup.find_all('div', class_='p-0 bg-light'):
        a = div.find('a', href=True)
        if not a: continue
        ul = a.find('ul', class_='list-group')
        if not ul: continue

        # Ders adÄ± â†’ ilk <li>, sÄ±nÄ±f bilgisini iÃ§eriyor
        items = ul.find_all('li')
        ders_adi = items[0].get_text(" ", strip=True)
        # SÄ±nÄ±f bilgisini daha kesin bir ÅŸekilde Ã§Ä±kar
        sinif_text = ""
        for li in items:
            text = li.get_text(" ", strip=True)
            if "SÄ±nÄ±f" in text and any(char.isdigit() for char in text):
                sinif_text = text
                break
        link = requests.compat.urljoin(resp.url, a['href'].strip())

        dersler.append({"isim": ders_adi,
                        "sinif": sinif_text,
                        "link": link})
    if not dersler:
        # Bu durumu Ã§aÄŸÄ±ran fonksiyona bildirmek iÃ§in boÅŸ liste yeterli.
        pass
    return dersler

def scrape_data():
    """Verileri Ã§eker ve ilerlemeyi yield ile anlÄ±k olarak bildirir."""
    siniflar = ["9","10","11","12"]
    tum_veri = {}
    link_index = {}

    yield {"type": "progress", "message": "Veri Ã§ekme iÅŸlemi baÅŸlatÄ±lÄ±yor..."}

    # AdÄ±m 1: Toplam iÅŸ yÃ¼kÃ¼nÃ¼ hesapla (tÃ¼m alanlarÄ±n sayÄ±sÄ±nÄ± bul)
    yield {"type": "progress", "message": "Toplam iÅŸ yÃ¼kÃ¼ hesaplanÄ±yor..."}
    all_alanlar_by_sinif = {sinif: get_alanlar(sinif) for sinif in siniflar}
    total_alan_count = sum(len(alan_list) for alan_list in all_alanlar_by_sinif.values())

    if total_alan_count == 0:
        yield {"type": "warning", "message": "Ä°ÅŸlenecek hiÃ§ alan bulunamadÄ±. Ä°ÅŸlem sonlandÄ±rÄ±lÄ±yor."}
        yield {"type": "done", "data": {"alanlar": {}, "ortak_alan_indeksi": {}}}
        return

    yield {"type": "progress", "message": f"Toplam {total_alan_count} alan iÅŸlenecek."}

    processed_alan_count = 0
    start_time = time.time()

    for sinif in siniflar:
        alanlar = all_alanlar_by_sinif[sinif]
        if not alanlar:
            yield {"type": "warning", "message": f"UyarÄ±: {sinif}. sÄ±nÄ±f iÃ§in alan bulunamadÄ±."}
            continue

        for i, alan in enumerate(alanlar):
            # Ä°lerleme ve zaman tahmini
            processed_alan_count += 1
            elapsed_time = time.time() - start_time
            avg_time_per_alan = elapsed_time / processed_alan_count
            remaining_alanlar = total_alan_count - processed_alan_count
            estimated_remaining_time_seconds = remaining_alanlar * avg_time_per_alan
            
            # ZamanÄ± dakika ve saniye olarak formatla
            mins, secs = divmod(estimated_remaining_time_seconds, 60)
            estimation_str = f"Tahmini kalan sÃ¼re: {int(mins)} dakika {int(secs)} saniye"

            alan_id = alan["id"]
            alan_adi = alan["isim"]
            yield {
                "type": "progress",
                "message": f"[{sinif}. SÄ±nÄ±f] Alan iÅŸleniyor: {alan_adi} ({processed_alan_count}/{total_alan_count})",
                "estimation": estimation_str
            }
            ders_listesi = get_dersler_for_alan(alan_id, alan["isim"], sinif)
            alan_entry = tum_veri.setdefault(alan_id, {"isim": alan_adi, "dersler": {}})
            for d in ders_listesi:
                ders_link = d["link"]
                # SÄ±nÄ±f numarasÄ±nÄ± "11.SÄ±nÄ±f" metninden Ã§Ä±kar
                sinif_num = d["sinif"].replace(".SÄ±nÄ±f", "").strip()
                # Ders linkini anahtar olarak kullanarak dersleri grupla
                ders_entry = alan_entry["dersler"].setdefault(ders_link, {
                    "isim": d["isim"],
                    "siniflar": set()
                })
                ders_entry["siniflar"].add(sinif_num)
                # Bu dersin (linkin) hangi alanlarda olduÄŸunu takip et
                link_index.setdefault(ders_link, set()).add(alan_id)

    # JSON uyumluluÄŸu iÃ§in set'leri listeye Ã§evir
    for alan_id in tum_veri:
        for ders_link in tum_veri[alan_id]["dersler"]:
            tum_veri[alan_id]["dersler"][ders_link]["siniflar"] = sorted(list(tum_veri[alan_id]["dersler"][ders_link]["siniflar"]), key=int)
    for link in link_index:
        link_index[link] = sorted(list(link_index[link]))

    yield {"type": "progress", "message": "Ä°ÅŸlem tamamlandÄ±. Veriler birleÅŸtiriliyor..."}
    final_data = {"alanlar": tum_veri, "ortak_alan_indeksi": link_index}
    # Son olarak, tÃ¼m veriyi 'done' tipiyle gÃ¶nder
    yield {"type": "done", "data": final_data}

def main():
    # Generator'dan gelen tÃ¼m veriyi topla
    scraped_data = [item for item in scrape_data() if item['type'] == 'done'][0]['data']
    tum_veri = scraped_data["alanlar"]
    link_index = scraped_data["ortak_alan_indeksi"]
    # ðŸ–¨ï¸ Terminal Ã§Ä±ktÄ±sÄ±
    for alan_id, alan_data in sorted(tum_veri.items(), key=lambda item: item[1]['isim']):
        print(f"\n{alan_data['isim']} ({alan_id})")
        # Dersleri isme gÃ¶re sÄ±rala
        sorted_dersler = sorted(alan_data["dersler"].items(), key=lambda item: item[1]["isim"])
        for ders_link, d in sorted_dersler:
            # SÄ±nÄ±flarÄ± birleÅŸtir: {"11", "12"} -> "11-12"
            sinif_str = "-".join(d['siniflar'])
            sinif_display_str = f"({sinif_str}. SÄ±nÄ±f)"
            # Ortak alan bilgisini oluÅŸtur
            ortak_alanlar = link_index.get(ders_link, [])
            ortak_str = ""
            if len(ortak_alanlar) > 1:
                ortak_str = f" ({len(ortak_alanlar)} ortak alan)"
            print(f"-> {d['isim']} {sinif_display_str}{ortak_str}")

    print("\n==== Ã–zet ====")
    toplam_alan = len(tum_veri)
    alan_bazinda_toplam_ders = sum(len(alan_data["dersler"]) for alan_data in tum_veri.values())
    benzersiz_toplam_ders = len({l for l in link_index})
    print(f"Toplam Alan: {toplam_alan}")
    print(f"Alan BazÄ±nda Toplam Ders: {alan_bazinda_toplam_ders}")
    print(f"Benzersiz Toplam Ders: {benzersiz_toplam_ders}")

if __name__ == "__main__":
    # print("âœ… Bu kod Ã§alÄ±ÅŸÄ±yor")  # Kontrol satÄ±rÄ± - server.py tarafÄ±ndan import edildiÄŸi iÃ§in yoruma alÄ±ndÄ±.
    main()
