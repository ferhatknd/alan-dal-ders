import requests
from bs4 import BeautifulSoup
import sys

BASE_OPTIONS_URL = "https://meslek.meb.gov.tr/cercevelistele.aspx"
BASE_DERS_ALT_URL = "https://meslek.meb.gov.tr/dmgoster.aspx"

# Sunucu tarafÄ±ndan engellenmemek iÃ§in bir tarayÄ±cÄ± gibi davranan User-Agent baÅŸlÄ±ÄŸÄ± ekleyelim.
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

def get_alanlar(sinif_kodu="9"):
    try:
        resp = requests.get(BASE_OPTIONS_URL, params={"sinif_kodu": sinif_kodu, "kurum_id":"1"}, headers=HEADERS)
        resp.raise_for_status()  # 4xx veya 5xx HTTP durum kodlarÄ±nda hata fÄ±rlatÄ±r.
    except requests.exceptions.RequestException as e:
        print(f"âš ï¸ AlanlarÄ± Ã§ekerken aÄŸ hatasÄ± (sÄ±nÄ±f {sinif_kodu}): {e}", file=sys.stderr)
        return []

    resp.encoding = resp.apparent_encoding
    soup = BeautifulSoup(resp.text, "html.parser")
    sel = soup.find('select', id="ContentPlaceHolder1_drpalansec")
    if not sel:
        print(f"âš ï¸ Alan listesi bulunamadÄ± (sÄ±nÄ±f {sinif_kodu})", file=sys.stderr)
        return []
    alanlar = []
    for opt in sel.find_all('option'):
        val = opt.get('value','').strip()
        name = opt.text.strip()
        if val and val not in ("00","0"):
            alanlar.append({"id": val, "isim": name})
    return alanlar

def get_dersler_for_alan(alan_id, alan_adi, sinif_kodu="9"):
    try:
        resp = requests.get(BASE_DERS_ALT_URL, params={"sinif_kodu": sinif_kodu, "kurum_id":"1", "alan_id":alan_id}, headers=HEADERS)
        resp.raise_for_status() # 4xx veya 5xx HTTP durum kodlarÄ±nda hata fÄ±rlatÄ±r.
    except requests.exceptions.RequestException as e:
        print(f"âš ï¸ Dersleri Ã§ekerken aÄŸ hatasÄ± ({alan_adi}): {e}", file=sys.stderr)
        return []

    resp.encoding = resp.apparent_encoding
    soup = BeautifulSoup(resp.text, "html.parser")

    dersler = []
    for div in soup.find_all('div', class_='p-0 bg-light'):
        a = div.find('a', href=True)
        if not a: continue
        ul = a.find('ul', class_='list-group')
        if not ul: continue

        # Ders adÄ± â†’ ilk <li>, sÄ±nÄ±f bilgisini iÃ§eriyor
        items = ul.find_all('li')
        ders_adi = items[0].get_text(" ", strip=True)
        # SÄ±nÄ±f bilgisini daha kesin bir ÅŸekilde Ã§Ä±kar
        sinif_text = ""
        for li in items:
            text = li.get_text(" ", strip=True)
            if "SÄ±nÄ±f" in text and any(char.isdigit() for char in text):
                sinif_text = text
                break
        link = requests.compat.urljoin(resp.url, a['href'].strip())

        dersler.append({"isim": ders_adi,
                        "sinif": sinif_text,
                        "link": link})
    if not dersler:
        print(f"âš ï¸ Ders bulunamadÄ±: {alan_adi} ({alan_id})", file=sys.stderr)
    return dersler

def scrape_data():
    siniflar = ["9","10","11","12"]
    tum_veri = {}
    link_index = {}

    print("Script baÅŸladÄ±...")

    for sinif in siniflar:
        print(f"{sinif}. sÄ±nÄ±f alanlarÄ± Ã§ekiliyor...")
        for alan in get_alanlar(sinif):
            alan_id = alan["id"]
            ders_listesi = get_dersler_for_alan(alan_id, alan["isim"], sinif)
            alan_entry = tum_veri.setdefault(alan_id, {"isim": alan["isim"], "dersler": {}})
            for d in ders_listesi:
                ders_link = d["link"]
                # SÄ±nÄ±f numarasÄ±nÄ± "11.SÄ±nÄ±f" metninden Ã§Ä±kar
                sinif_num = d["sinif"].replace(".SÄ±nÄ±f", "").strip()
                # Ders linkini anahtar olarak kullanarak dersleri grupla
                ders_entry = alan_entry["dersler"].setdefault(ders_link, {
                    "isim": d["isim"],
                    "siniflar": set()
                })
                ders_entry["siniflar"].add(sinif_num)
                # Bu dersin (linkin) hangi alanlarda olduÄŸunu takip et
                link_index.setdefault(ders_link, set()).add(alan_id)

    # JSON uyumluluÄŸu iÃ§in set'leri listeye Ã§evir
    for alan_id in tum_veri:
        for ders_link in tum_veri[alan_id]["dersler"]:
            tum_veri[alan_id]["dersler"][ders_link]["siniflar"] = sorted(list(tum_veri[alan_id]["dersler"][ders_link]["siniflar"]), key=int)
    for link in link_index:
        link_index[link] = sorted(list(link_index[link]))

    return {"alanlar": tum_veri, "ortak_alan_indeksi": link_index}

def main():
    scraped_data = scrape_data()
    tum_veri = scraped_data["alanlar"]
    link_index = scraped_data["ortak_alan_indeksi"]
    # ğŸ–¨ï¸ Terminal Ã§Ä±ktÄ±sÄ±
    for alan_id, alan_data in sorted(tum_veri.items(), key=lambda item: item[1]['isim']):
        print(f"\n{alan_data['isim']} ({alan_id})")
        # Dersleri isme gÃ¶re sÄ±rala
        sorted_dersler = sorted(alan_data["dersler"].items(), key=lambda item: item[1]["isim"])
        for ders_link, d in sorted_dersler:
            # SÄ±nÄ±flarÄ± birleÅŸtir: {"11", "12"} -> "11-12"
            sinif_str = "-".join(d['siniflar'])
            sinif_display_str = f"({sinif_str}. SÄ±nÄ±f)"
            # Ortak alan bilgisini oluÅŸtur
            ortak_alanlar = link_index.get(ders_link, [])
            ortak_str = ""
            if len(ortak_alanlar) > 1:
                ortak_str = f" ({len(ortak_alanlar)} ortak alan)"
            print(f"-> {d['isim']} {sinif_display_str}{ortak_str}")

    print("\n==== Ã–zet ====")
    toplam_alan = len(tum_veri)
    alan_bazinda_toplam_ders = sum(len(alan_data["dersler"]) for alan_data in tum_veri.values())
    benzersiz_toplam_ders = len({l for l in link_index})
    print(f"Toplam Alan: {toplam_alan}")
    print(f"Alan BazÄ±nda Toplam Ders: {alan_bazinda_toplam_ders}")
    print(f"Benzersiz Toplam Ders: {benzersiz_toplam_ders}")

if __name__ == "__main__":
    # print("âœ… Bu kod Ã§alÄ±ÅŸÄ±yor")  # Kontrol satÄ±rÄ± - server.py tarafÄ±ndan import edildiÄŸi iÃ§in yoruma alÄ±ndÄ±.
    main()
